{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knKZwzSB_nGS",
        "outputId": "d81cc5c6-bed3-48a8-c800-aa669dd08347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext, langdetect\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498210 sha256=882fc771ed5c4dfcd3f5d0140ac59afb7f64e9cb96500883b6bff57eeaad2d81\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=a70fbe9521f34b076af5b86acb9b73418e9b5cf42efaa125b22893d21b4be6db\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built fasttext langdetect\n",
            "Installing collected packages: pybind11, langdetect, fasttext\n",
            "Successfully installed fasttext-0.9.3 langdetect-1.0.9 pybind11-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn imbalanced-learn\n",
        "!pip install transformers datasets torch accelerate\n",
        "!pip install fasttext langdetect openpyxl joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QnfnP_qMKS2"
      },
      "source": [
        "# last version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4RiCvmuKLBJ",
        "outputId": "45a316b5-832d-4fe3-ad19-fcfe068f49eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted\n",
            "================================================================================\n",
            "CLASSICAL MODELS PIPELINE (Shared Drive + Data Maximization)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1] Loading and cleaning data...\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/Main.xlsx...\n",
            "    MAIN: 10800 rows\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-1.xlsx...\n",
            "    /content/drive/MyDrive/fignews_shared_project/data/IAA-1.xlsx: 1200 rows\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-2.xlsx...\n",
            "    /content/drive/MyDrive/fignews_shared_project/data/IAA-2.xlsx: 1200 rows\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-3.xlsx...\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-4.xlsx...\n",
            "\n",
            "  Total IAA: 2400 rows\n",
            "\n",
            "[STEP 2] Creating train/test splits...\n",
            "\n",
            "  Applying majority vote...\n",
            "\n",
            "  Applying majority vote...\n",
            "\n",
            "  Training: 11760 samples\n",
            "  Test: 240 samples\n",
            "\n",
            "================================================================================\n",
            "TRAINING ARABIC RANDOM FOREST\n",
            "================================================================================\n",
            "\n",
            "[Arabic RF] Loading FastText...\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.bin.gz\n",
            "\n",
            "  ✓ FastText loaded.\n",
            "\n",
            "[Arabic RF] Training...\n",
            "  ✓ Arabic RF trained.\n",
            "\n",
            "================================================================================\n",
            "TRAINING ENGLISH RANDOM FOREST\n",
            "================================================================================\n",
            "\n",
            "[English RF] Training...\n",
            "  ✓ English RF trained.\n",
            "\n",
            "Completed! Models saved to /content/drive/MyDrive/fignews_shared_project/models/classical/\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "FIGNEWS-2024: CLASSICAL MODELS (TEAM VERSION - SHARED DRIVE)\n",
        "=============================================================\n",
        "- Uses shared Google Drive for storage\n",
        "- Saves only final models\n",
        "- Data Logic: MAXIMIZE DATA (Filters by Text Availability, NOT Source Language label)\n",
        "  * Arabic Model: Uses Text if Source=Arabic, otherwise uses Arabic MT.\n",
        "  * English Model: Uses Text if Source=English, otherwise uses English MT.\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# GOOGLE DRIVE MOUNT (With Force Remount)\n",
        "# ============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"✓ Google Drive mounted\")\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "import os\n",
        "import warnings\n",
        "import re\n",
        "import string\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CLASSICAL MODELS PIPELINE (Shared Drive + Data Maximization)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Pipeline configuration\"\"\"\n",
        "\n",
        "    # ========== SHARED DRIVE PATHS ==========\n",
        "    BASE_PATH = \"/content/drive/MyDrive/fignews_shared_project/\"\n",
        "\n",
        "    # Data paths\n",
        "    MAIN_FILE = BASE_PATH + \"data/Main.xlsx\"\n",
        "    IAA_FILES = [\n",
        "        BASE_PATH + \"data/IAA-1.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-2.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-3.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-4.xlsx\"\n",
        "    ]\n",
        "\n",
        "    # Output directory\n",
        "    OUTPUT_DIR = BASE_PATH + \"models/classical/\"\n",
        "\n",
        "    # Label mapping\n",
        "    LABEL_MAP = {\n",
        "        'Unbiased': 'Unbiased',\n",
        "        'Biased against Palestine': 'Biased Against Palestine',\n",
        "        'Biased Against Palestine': 'Biased Against Palestine',\n",
        "        'Biased against Israel': 'Biased Against Israel',\n",
        "        'Biased Against Israel': 'Biased Against Israel',\n",
        "        'Unclear': 'Others',\n",
        "        'Biased against others': 'Others',\n",
        "        'Biased against both': 'Others',\n",
        "        'Biased against both Palestine and Israel': 'Others',\n",
        "        'Not Applicable': 'Others',\n",
        "        'Others': 'Others'\n",
        "    }\n",
        "\n",
        "    TARGET_LABELS = ['Unbiased', 'Biased Against Palestine',\n",
        "                     'Biased Against Israel', 'Others']\n",
        "    LABEL2ID = {label: idx for idx, label in enumerate(TARGET_LABELS)}\n",
        "    ID2LABEL = {idx: label for label, idx in LABEL2ID.items()}\n",
        "\n",
        "    # FastText\n",
        "    FASTTEXT_AR_MODEL = \"cc.ar.300.bin\"\n",
        "    FASTTEXT_DIM = 300\n",
        "\n",
        "    # Training parameters\n",
        "    IAA_TRAIN_SPLIT = 0.8\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PREPROCESSING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def preprocess_classical_arabic(text: str) -> str:\n",
        "    \"\"\"Extended preprocessing for Arabic Classical Model.\"\"\"\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    text = text.replace(':=:', ' ')\n",
        "    text = re.sub(r'[a-zA-Z]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    arabic_punctuation = '،؛؟!()[]{}\"\"\"\\'\\'`'\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation + arabic_punctuation))\n",
        "    text = re.sub(r'[إأآا]', 'ا', text)\n",
        "    text = re.sub(r'ى', 'ي', text)\n",
        "    text = re.sub(r'ة', 'ه', text)\n",
        "    text = re.sub(r'ئ', 'ي', text)\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def preprocess_classical_english(text: str) -> str:\n",
        "    \"\"\"Extended preprocessing for English Classical Model.\"\"\"\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    text = text.replace(':=:', ' ')\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.lower()\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def clean_urls_and_format(text: str) -> str:\n",
        "    \"\"\"Basic cleaning for initial loading.\"\"\"\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    text = text.replace(':=:', ' ')\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING & PREPARATION\n",
        "# ============================================================================\n",
        "\n",
        "def filter_valid_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    CRITICAL CHANGE: Do NOT filter by 'Source Language' column.\n",
        "    Instead, keep rows where valid text exists in Text, Arabic MT, or English MT.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Columns to check for content\n",
        "    check_cols = [c for c in ['Text', 'Arabic MT', 'English MT'] if c in df.columns]\n",
        "\n",
        "    if not check_cols:\n",
        "        return df\n",
        "\n",
        "    # Keep row if ANY of these columns has non-empty text\n",
        "    # (Checks if length of stripped text > 0)\n",
        "    mask = df[check_cols].apply(\n",
        "        lambda x: x.astype(str).str.strip().str.len() > 0\n",
        "    ).any(axis=1)\n",
        "\n",
        "    df_filtered = df[mask].copy()\n",
        "\n",
        "    dropped = len(df) - len(df_filtered)\n",
        "    if dropped > 0:\n",
        "        print(f\"    Dropped {dropped} rows with no text content in any column.\")\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "\n",
        "def load_and_clean_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load MAIN and IAA files.\"\"\"\n",
        "    print(\"\\n[STEP 1] Loading and cleaning data...\")\n",
        "\n",
        "    if not os.path.exists(Config.MAIN_FILE):\n",
        "        print(f\"ERROR: File not found at {Config.MAIN_FILE}\")\n",
        "        raise FileNotFoundError(f\"{Config.MAIN_FILE} not found!\")\n",
        "\n",
        "    print(f\"  Loading {Config.MAIN_FILE}...\")\n",
        "    main_df = pd.read_excel(Config.MAIN_FILE)\n",
        "\n",
        "    main_df = main_df[main_df['Bias'].notna() & (main_df['Bias'] != '')]\n",
        "    main_df['Bias'] = main_df['Bias'].astype(str).str.strip()\n",
        "\n",
        "    # Clean text columns\n",
        "    for col in ['Text', 'Arabic MT', 'English MT']:\n",
        "        if col in main_df.columns:\n",
        "            main_df[col] = main_df[col].apply(clean_urls_and_format)\n",
        "\n",
        "    # Filter based on data availability (not source language label)\n",
        "    main_df = filter_valid_data(main_df)\n",
        "    print(f\"    MAIN: {len(main_df)} rows\")\n",
        "\n",
        "    # Load IAA\n",
        "    iaa_dfs = []\n",
        "    for iaa_file in Config.IAA_FILES:\n",
        "        if os.path.exists(iaa_file):\n",
        "            print(f\"  Loading {iaa_file}...\")\n",
        "            iaa_df_temp = pd.read_excel(iaa_file)\n",
        "\n",
        "            if 'Bais' in iaa_df_temp.columns:\n",
        "                iaa_df_temp['Bias'] = iaa_df_temp['Bais']\n",
        "\n",
        "            iaa_df_temp = iaa_df_temp[iaa_df_temp['Bias'].notna() & (iaa_df_temp['Bias'] != '')]\n",
        "            iaa_df_temp['Bias'] = iaa_df_temp['Bias'].astype(str).str.strip()\n",
        "\n",
        "            if len(iaa_df_temp) > 0:\n",
        "                for col in ['Text', 'Arabic MT', 'English MT']:\n",
        "                    if col in iaa_df_temp.columns:\n",
        "                        iaa_df_temp[col] = iaa_df_temp[col].apply(clean_urls_and_format)\n",
        "\n",
        "                # Filter valid data\n",
        "                iaa_df_temp = filter_valid_data(iaa_df_temp)\n",
        "                iaa_dfs.append(iaa_df_temp)\n",
        "                print(f\"    {iaa_file}: {len(iaa_df_temp)} rows\")\n",
        "\n",
        "    iaa_df = pd.concat(iaa_dfs, ignore_index=True) if iaa_dfs else pd.DataFrame()\n",
        "    print(f\"\\n  Total IAA: {len(iaa_df)} rows\")\n",
        "\n",
        "    return main_df, iaa_df\n",
        "\n",
        "\n",
        "def map_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df['Bias_Mapped'] = df['Bias'].map(Config.LABEL_MAP)\n",
        "    df['Bias_Mapped'] = df['Bias_Mapped'].fillna('Others')\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_majority_vote(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    print(\"\\n  Applying majority vote...\")\n",
        "    df['Text_ID'] = df['ID'].astype(str) + \"_\" + df['Text'].str[:20]\n",
        "    gold_rows = []\n",
        "    for text_id, group in df.groupby('Text_ID'):\n",
        "        labels = group['Bias_Mapped'].tolist()\n",
        "        majority_label = Counter(labels).most_common(1)[0][0]\n",
        "        gold_row = group.iloc[0].copy()\n",
        "        gold_row['Bias_Mapped'] = majority_label\n",
        "        gold_rows.append(gold_row)\n",
        "    return pd.DataFrame(gold_rows)\n",
        "\n",
        "\n",
        "def create_train_test_split(main_df: pd.DataFrame, iaa_df: pd.DataFrame):\n",
        "    print(\"\\n[STEP 2] Creating train/test splits...\")\n",
        "    unique_ids = (iaa_df['Text_ID'].unique() if 'Text_ID' in iaa_df.columns else iaa_df['ID'].unique())\n",
        "    train_ids, test_ids = train_test_split(unique_ids, test_size=(1 - Config.IAA_TRAIN_SPLIT), random_state=Config.RANDOM_STATE)\n",
        "\n",
        "    if 'Text_ID' in iaa_df.columns:\n",
        "        iaa_train = iaa_df[iaa_df['Text_ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['Text_ID'].isin(test_ids)].copy()\n",
        "    else:\n",
        "        iaa_train = iaa_df[iaa_df['ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['ID'].isin(test_ids)].copy()\n",
        "\n",
        "    train_df = pd.concat([main_df, apply_majority_vote(iaa_train)], ignore_index=True)\n",
        "    test_df = apply_majority_vote(iaa_test)\n",
        "\n",
        "    print(f\"\\n  Training: {len(train_df)} samples\")\n",
        "    print(f\"  Test: {len(test_df)} samples\")\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "def prepare_text_columns(df: pd.DataFrame, target_lang: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    CRITICAL DATA LOGIC: Select text column to MAXIMIZE data usage.\n",
        "    Does NOT filter by Source Language, only prioritizes columns.\n",
        "\n",
        "    Logic:\n",
        "    1. If target is 'arabic':\n",
        "       - If Source=Arabic, use 'Text'.\n",
        "       - Otherwise (English/Unknown), use 'Arabic MT'.\n",
        "    2. If target is 'english':\n",
        "       - If Source=English, use 'Text'.\n",
        "       - Otherwise (Arabic/Unknown), use 'English MT'.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    if target_lang == 'arabic':\n",
        "        # Use Text if source is explicitly Arabic, else default to MT\n",
        "        df['ModelText'] = df.apply(\n",
        "            lambda row: row['Text'] if 'Arabic' in str(row.get('Source Language', ''))\n",
        "            else row['Arabic MT'],\n",
        "            axis=1\n",
        "        )\n",
        "    else: # english\n",
        "        # Use Text if source is explicitly English, else default to MT\n",
        "        df['ModelText'] = df.apply(\n",
        "            lambda row: row['Text'] if 'English' in str(row.get('Source Language', ''))\n",
        "            else row['English MT'],\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    # Drop rows where the *selected* text is empty\n",
        "    initial_len = len(df)\n",
        "    df = df[df['ModelText'].notna() & (df['ModelText'].astype(str).str.strip() != '')]\n",
        "    if len(df) < initial_len:\n",
        "        print(f\"  Warning: Dropped {initial_len - len(df)} rows due to missing '{target_lang}' content\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MODELS (RF)\n",
        "# ============================================================================\n",
        "\n",
        "class ArabicRFModel:\n",
        "    def __init__(self):\n",
        "        self.ft_model = None\n",
        "        self.rf_model = None\n",
        "        self.label_encoder = Config.LABEL2ID\n",
        "\n",
        "    def load_fasttext(self):\n",
        "        print(\"\\n[Arabic RF] Loading FastText...\")\n",
        "        if not os.path.exists(Config.FASTTEXT_AR_MODEL):\n",
        "            try:\n",
        "                fasttext.util.download_model('ar', if_exists='ignore')\n",
        "            except: pass\n",
        "        try:\n",
        "            self.ft_model = fasttext.load_model(Config.FASTTEXT_AR_MODEL)\n",
        "            print(\"  ✓ FastText loaded.\")\n",
        "        except: print(\"  Error loading FastText.\")\n",
        "\n",
        "    def vectorize_text(self, text: str):\n",
        "        if not isinstance(text, str) or len(text.strip()) == 0: return np.zeros(Config.FASTTEXT_DIM)\n",
        "        if self.ft_model is None: return np.zeros(Config.FASTTEXT_DIM)\n",
        "        words = text.split()\n",
        "        vecs = [self.ft_model.get_word_vector(w) for w in words if w.strip()]\n",
        "        return np.mean(vecs, axis=0) if vecs else np.zeros(Config.FASTTEXT_DIM)\n",
        "\n",
        "    def train(self, df):\n",
        "        print(\"\\n[Arabic RF] Training...\")\n",
        "        df['Text_Processed'] = df['ModelText'].apply(preprocess_classical_arabic)\n",
        "        X = np.array([self.vectorize_text(t) for t in df['Text_Processed']])\n",
        "        y = df['Bias_Mapped'].map(self.label_encoder).values\n",
        "\n",
        "        # SMOTE\n",
        "        min_samp = min(Counter(y).values())\n",
        "        k = min(5, min_samp - 1) if min_samp > 1 else 1\n",
        "        if min_samp > 1:\n",
        "            X, y = SMOTE(random_state=42, k_neighbors=k).fit_resample(X, y)\n",
        "\n",
        "        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "        self.rf_model.fit(X, y)\n",
        "        print(\"  ✓ Arabic RF trained.\")\n",
        "\n",
        "    def predict(self, df):\n",
        "        df['Text_Processed'] = df['ModelText'].apply(preprocess_classical_arabic)\n",
        "        X = np.array([self.vectorize_text(t) for t in df['Text_Processed']])\n",
        "        return [Config.ID2LABEL[p] for p in self.rf_model.predict(X)]\n",
        "\n",
        "    def save(self, path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        joblib.dump(self.rf_model, os.path.join(path, 'rf_arabic.pkl'))\n",
        "        joblib.dump({'label_encoder': self.label_encoder}, os.path.join(path, 'rf_arabic_metadata.pkl'))\n",
        "\n",
        "class EnglishRFModel:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = None\n",
        "        self.rf_model = None\n",
        "        self.label_encoder = Config.LABEL2ID\n",
        "\n",
        "    def train(self, df):\n",
        "        print(\"\\n[English RF] Training...\")\n",
        "        df['Text_Processed'] = df['ModelText'].apply(preprocess_classical_english)\n",
        "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1,2))\n",
        "        X = self.vectorizer.fit_transform(df['Text_Processed'])\n",
        "        y = df['Bias_Mapped'].map(self.label_encoder).values\n",
        "\n",
        "        # SMOTE\n",
        "        min_samp = min(Counter(y).values())\n",
        "        k = min(5, min_samp - 1) if min_samp > 1 else 1\n",
        "        if min_samp > 1:\n",
        "            X, y = SMOTE(random_state=42, k_neighbors=k).fit_resample(X, y)\n",
        "\n",
        "        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "        self.rf_model.fit(X, y)\n",
        "        print(\"  ✓ English RF trained.\")\n",
        "\n",
        "    def predict(self, df):\n",
        "        df['Text_Processed'] = df['ModelText'].apply(preprocess_classical_english)\n",
        "        X = self.vectorizer.transform(df['Text_Processed'])\n",
        "        return [Config.ID2LABEL[p] for p in self.rf_model.predict(X)]\n",
        "\n",
        "    def save(self, path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        joblib.dump(self.rf_model, os.path.join(path, 'rf_english.pkl'))\n",
        "        joblib.dump(self.vectorizer, os.path.join(path, 'tfidf_english.pkl'))\n",
        "        joblib.dump({'label_encoder': self.label_encoder}, os.path.join(path, 'rf_english_metadata.pkl'))\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    np.random.seed(Config.RANDOM_STATE)\n",
        "\n",
        "    try: main_df, iaa_df = load_and_clean_data()\n",
        "    except FileNotFoundError: return\n",
        "\n",
        "    main_df = map_labels(main_df)\n",
        "    iaa_df = map_labels(iaa_df) if len(iaa_df) > 0 else iaa_df\n",
        "    train_df, test_df = create_train_test_split(main_df, iaa_df)\n",
        "\n",
        "    # Train Arabic RF\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\nTRAINING ARABIC RANDOM FOREST\\n\" + \"=\"*80)\n",
        "    train_ar = prepare_text_columns(train_df, 'arabic')\n",
        "    test_ar = prepare_text_columns(test_df, 'arabic')\n",
        "    ar_model = ArabicRFModel()\n",
        "    ar_model.load_fasttext()\n",
        "    ar_model.train(train_ar)\n",
        "    ar_model.save(Config.OUTPUT_DIR)\n",
        "\n",
        "    # Train English RF\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\nTRAINING ENGLISH RANDOM FOREST\\n\" + \"=\"*80)\n",
        "    train_en = prepare_text_columns(train_df, 'english')\n",
        "    test_en = prepare_text_columns(test_df, 'english')\n",
        "    en_model = EnglishRFModel()\n",
        "    en_model.train(train_en)\n",
        "    en_model.save(Config.OUTPUT_DIR)\n",
        "\n",
        "    print(f\"\\nCompleted! Models saved to {Config.OUTPUT_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySceaQYiSnKq",
        "outputId": "f8356887-0457-42b9-bcfb-1fa255cfa8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "========================================\n",
            "EVALUATING ARABIC MODEL\n",
            "========================================\n",
            "Loading FastText (this may take a moment)...\n",
            "✓ FastText loaded\n",
            "Loading data to recreate test set...\n",
            "Predicting on 240 samples...\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "   Biased Against Israel     1.0000    1.0000    1.0000         1\n",
            "Biased Against Palestine     0.8889    0.8533    0.8707        75\n",
            "                  Others     0.7500    0.7059    0.7273        17\n",
            "                Unbiased     0.9205    0.9456    0.9329       147\n",
            "\n",
            "                accuracy                         0.9000       240\n",
            "               macro avg     0.8899    0.8762    0.8827       240\n",
            "            weighted avg     0.8989    0.9000    0.8992       240\n",
            "\n",
            "\n",
            "========================================\n",
            "EVALUATING ENGLISH MODEL\n",
            "========================================\n",
            "✓ Models loaded\n",
            "Loading data to recreate test set...\n",
            "Predicting on 240 samples...\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "   Biased Against Israel     0.5000    1.0000    0.6667         1\n",
            "Biased Against Palestine     0.8889    0.8533    0.8707        75\n",
            "                  Others     0.6875    0.6471    0.6667        17\n",
            "                Unbiased     0.9067    0.9252    0.9158       147\n",
            "\n",
            "                accuracy                         0.8833       240\n",
            "               macro avg     0.7458    0.8564    0.7800       240\n",
            "            weighted avg     0.8839    0.8833    0.8831       240\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "FIGNEWS-2024: STANDALONE EVALUATION (CLASSICAL MODELS) - FIXED v2\n",
        "=================================================================\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# 1. SETUP & CONFIGURATION\n",
        "# ============================================================================\n",
        "import os\n",
        "import joblib\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Force remount\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "class Config:\n",
        "    BASE_PATH = \"/content/drive/MyDrive/fignews_shared_project/\"\n",
        "    MAIN_FILE = BASE_PATH + \"data/Main.xlsx\"\n",
        "    IAA_FILES = [\n",
        "        BASE_PATH + \"data/IAA-1.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-2.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-3.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-4.xlsx\"\n",
        "    ]\n",
        "    OUTPUT_DIR = BASE_PATH + \"models/classical/\"\n",
        "\n",
        "    LABEL_MAP = {\n",
        "        'Unbiased': 'Unbiased',\n",
        "        'Biased against Palestine': 'Biased Against Palestine',\n",
        "        'Biased Against Palestine': 'Biased Against Palestine',\n",
        "        'Biased against Israel': 'Biased Against Israel',\n",
        "        'Biased Against Israel': 'Biased Against Israel',\n",
        "        'Unclear': 'Others',\n",
        "        'Biased against others': 'Others',\n",
        "        'Biased against both': 'Others',\n",
        "        'Biased against both Palestine and Israel': 'Others',\n",
        "        'Not Applicable': 'Others',\n",
        "        'Others': 'Others'\n",
        "    }\n",
        "    TARGET_LABELS = ['Unbiased', 'Biased Against Palestine', 'Biased Against Israel', 'Others']\n",
        "    LABEL2ID = {label: idx for idx, label in enumerate(TARGET_LABELS)}\n",
        "    ID2LABEL = {idx: label for label, idx in LABEL2ID.items()}\n",
        "\n",
        "    FASTTEXT_AR_MODEL = \"cc.ar.300.bin\"\n",
        "    FASTTEXT_DIM = 300\n",
        "    IAA_TRAIN_SPLIT = 0.8\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "# ============================================================================\n",
        "# 2. PREPROCESSING & DATA FUNCTIONS (Fixed)\n",
        "# ============================================================================\n",
        "def preprocess_classical_arabic(text):\n",
        "    \"\"\"Extended preprocessing for Arabic.\"\"\"\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text).replace(':=:', ' ')\n",
        "    # Remove English chars and digits\n",
        "    text = re.sub(r'[a-zA-Z]', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuation\n",
        "    arabic_punc = '،؛؟!()[]{}\"\"\"\\'\\'`'\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation + arabic_punc))\n",
        "    # Normalize Arabic\n",
        "    text = re.sub(r'[إأآا]', 'ا', text)\n",
        "    text = re.sub(r'ى', 'ي', text)\n",
        "    text = re.sub(r'ة', 'ه', text)\n",
        "    text = re.sub(r'ئ', 'ي', text)\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def preprocess_classical_english(text):\n",
        "    \"\"\"Extended preprocessing for English.\"\"\"\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text).replace(':=:', ' ')\n",
        "    # Remove hashtags and mentions\n",
        "    text = re.sub(r'#\\w+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove digits\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove punctuation and lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def clean_urls_and_format(text):\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    return re.sub(r'\\s+', ' ', re.sub(r'http\\S+|www\\.\\S+', '', text).replace(':=:', ' ')).strip()\n",
        "\n",
        "def filter_valid_data(df):\n",
        "    df = df.copy()\n",
        "    check_cols = [c for c in ['Text', 'Arabic MT', 'English MT'] if c in df.columns]\n",
        "    if not check_cols: return df\n",
        "    mask = df[check_cols].apply(lambda x: x.astype(str).str.strip().str.len() > 0).any(axis=1)\n",
        "    return df[mask].copy()\n",
        "\n",
        "def load_data():\n",
        "    print(\"Loading data to recreate test set...\")\n",
        "    if not os.path.exists(Config.MAIN_FILE):\n",
        "        print(f\"❌ Error: Cannot find {Config.MAIN_FILE}\")\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    main_df = pd.read_excel(Config.MAIN_FILE)\n",
        "    main_df = main_df[main_df['Bias'].notna()]\n",
        "    main_df['Bias'] = main_df['Bias'].astype(str).str.strip()\n",
        "\n",
        "    for c in ['Text', 'Arabic MT', 'English MT']:\n",
        "        if c in main_df.columns: main_df[c] = main_df[c].apply(clean_urls_and_format)\n",
        "    main_df = filter_valid_data(main_df)\n",
        "\n",
        "    iaa_dfs = []\n",
        "    for f in Config.IAA_FILES:\n",
        "        if os.path.exists(f):\n",
        "            t = pd.read_excel(f)\n",
        "            if 'Bais' in t.columns: t['Bias'] = t['Bais']\n",
        "            t = t[t['Bias'].notna()]\n",
        "            t['Bias'] = t['Bias'].astype(str).str.strip()\n",
        "            for c in ['Text', 'Arabic MT', 'English MT']:\n",
        "                if c in t.columns: t[c] = t[c].apply(clean_urls_and_format)\n",
        "            iaa_dfs.append(filter_valid_data(t))\n",
        "    iaa_df = pd.concat(iaa_dfs, ignore_index=True) if iaa_dfs else pd.DataFrame()\n",
        "    return main_df, iaa_df\n",
        "\n",
        "def get_test_set():\n",
        "    main_df, iaa_df = load_data()\n",
        "    if main_df.empty: return pd.DataFrame()\n",
        "\n",
        "    # Map labels\n",
        "    for df in [main_df, iaa_df]:\n",
        "        if not df.empty:\n",
        "            df['Bias_Mapped'] = df['Bias'].map(Config.LABEL_MAP).fillna('Others')\n",
        "\n",
        "    # Majority Vote Logic\n",
        "    if iaa_df.empty:\n",
        "        print(\"Warning: No IAA files found. Using split from Main file only.\")\n",
        "        main_df['Text_ID'] = main_df['ID'].astype(str)\n",
        "        u_ids = main_df['Text_ID'].unique()\n",
        "        _, test_ids = train_test_split(u_ids, test_size=(1-Config.IAA_TRAIN_SPLIT), random_state=Config.RANDOM_STATE)\n",
        "        return main_df[main_df['Text_ID'].isin(test_ids)].copy()\n",
        "\n",
        "    iaa_df['Text_ID'] = iaa_df['ID'].astype(str) + \"_\" + iaa_df['Text'].str[:20]\n",
        "    gold_rows = []\n",
        "    for _, g in iaa_df.groupby('Text_ID'):\n",
        "        maj_label = Counter(g['Bias_Mapped']).most_common(1)[0][0]\n",
        "        r = g.iloc[0].copy()\n",
        "        r['Bias_Mapped'] = maj_label\n",
        "        gold_rows.append(r)\n",
        "    iaa_collapsed = pd.DataFrame(gold_rows)\n",
        "\n",
        "    # Split\n",
        "    u_ids = iaa_df['Text_ID'].unique()\n",
        "    _, test_ids = train_test_split(u_ids, test_size=(1-Config.IAA_TRAIN_SPLIT), random_state=Config.RANDOM_STATE)\n",
        "\n",
        "    # Return Test Set\n",
        "    return iaa_collapsed[iaa_collapsed['Text_ID'].isin(test_ids)].copy()\n",
        "\n",
        "def prepare_cols(df, lang):\n",
        "    df = df.copy()\n",
        "    if lang == 'arabic':\n",
        "        df['ModelText'] = df.apply(lambda r: r['Text'] if 'Arabic' in str(r.get('Source Language','')) else r['Arabic MT'], axis=1)\n",
        "    else:\n",
        "        df['ModelText'] = df.apply(lambda r: r['Text'] if 'English' in str(r.get('Source Language','')) else r['English MT'], axis=1)\n",
        "    return df[df['ModelText'].str.strip().str.len() > 0]\n",
        "\n",
        "# ============================================================================\n",
        "# 3. EVALUATION LOGIC\n",
        "# ============================================================================\n",
        "\n",
        "def evaluate_arabic():\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\nEVALUATING ARABIC MODEL\\n\" + \"=\"*40)\n",
        "\n",
        "    # 1. Load Model\n",
        "    model_path = os.path.join(Config.OUTPUT_DIR, 'rf_arabic.pkl')\n",
        "    if not os.path.exists(model_path): print(f\"❌ Model not found: {model_path}\"); return\n",
        "    rf_model = joblib.load(model_path)\n",
        "\n",
        "    # 2. Load FastText\n",
        "    if not os.path.exists(Config.FASTTEXT_AR_MODEL):\n",
        "         print(\"Downloading FastText...\")\n",
        "         fasttext.util.download_model('ar', if_exists='ignore')\n",
        "\n",
        "    print(\"Loading FastText (this may take a moment)...\")\n",
        "    ft_model = fasttext.load_model(Config.FASTTEXT_AR_MODEL)\n",
        "    print(\"✓ FastText loaded\")\n",
        "\n",
        "    # 3. Prepare Data\n",
        "    test_df = get_test_set()\n",
        "    if test_df.empty: print(\"❌ No test data found\"); return\n",
        "\n",
        "    test_ar = prepare_cols(test_df, 'arabic')\n",
        "\n",
        "    # 4. Predict\n",
        "    print(f\"Predicting on {len(test_ar)} samples...\")\n",
        "    test_ar['Text_Processed'] = test_ar['ModelText'].apply(preprocess_classical_arabic)\n",
        "\n",
        "    def vec(t):\n",
        "        w = t.split()\n",
        "        v = [ft_model.get_word_vector(x) for x in w if x.strip()]\n",
        "        return np.mean(v, axis=0) if v else np.zeros(300)\n",
        "\n",
        "    X = np.array([vec(t) for t in test_ar['Text_Processed']])\n",
        "    preds_idx = rf_model.predict(X)\n",
        "    preds_label = [Config.ID2LABEL[p] for p in preds_idx]\n",
        "\n",
        "    # 5. Report\n",
        "    print(classification_report(test_ar['Bias_Mapped'], preds_label, digits=4))\n",
        "\n",
        "def evaluate_english():\n",
        "    print(\"\\n\" + \"=\"*40 + \"\\nEVALUATING ENGLISH MODEL\\n\" + \"=\"*40)\n",
        "\n",
        "    # 1. Load Model & Vectorizer\n",
        "    model_path = os.path.join(Config.OUTPUT_DIR, 'rf_english.pkl')\n",
        "    vect_path = os.path.join(Config.OUTPUT_DIR, 'tfidf_english.pkl')\n",
        "\n",
        "    if not os.path.exists(model_path): print(f\"❌ Model not found: {model_path}\"); return\n",
        "    rf_model = joblib.load(model_path)\n",
        "    vectorizer = joblib.load(vect_path)\n",
        "    print(\"✓ Models loaded\")\n",
        "\n",
        "    # 2. Prepare Data\n",
        "    test_df = get_test_set()\n",
        "    if test_df.empty: print(\"❌ No test data found\"); return\n",
        "\n",
        "    test_en = prepare_cols(test_df, 'english')\n",
        "\n",
        "    # 3. Predict\n",
        "    print(f\"Predicting on {len(test_en)} samples...\")\n",
        "    test_en['Text_Processed'] = test_en['ModelText'].apply(preprocess_classical_english)\n",
        "    X = vectorizer.transform(test_en['Text_Processed'])\n",
        "\n",
        "    preds_idx = rf_model.predict(X)\n",
        "    preds_label = [Config.ID2LABEL[p] for p in preds_idx]\n",
        "\n",
        "    # 4. Report\n",
        "    print(classification_report(test_en['Bias_Mapped'], preds_label, digits=4))\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    evaluate_arabic()\n",
        "    evaluate_english()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02adf9c5ea414d3d844e5b264dad6724": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c400a5df0ed4907bc978fbea62cd598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce15792fca148eda46e17955389c803",
            "placeholder": "​",
            "style": "IPY_MODEL_193de67b596e4c57b7c64a3a07824776",
            "value": "Map: 100%"
          }
        },
        "193de67b596e4c57b7c64a3a07824776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce15792fca148eda46e17955389c803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2219587102284c03b7a17449a9d966d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d973ad205704896be97f44ca0f97c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b47045104a4dfda568bf89e8623c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c400a5df0ed4907bc978fbea62cd598",
              "IPY_MODEL_70fcea0c0d3049a2a97848fb58b4e4e6",
              "IPY_MODEL_e65a444dfc7042f5b55ed3d49fa330ac"
            ],
            "layout": "IPY_MODEL_02adf9c5ea414d3d844e5b264dad6724"
          }
        },
        "49dc357ec52b40b0a99a2a3a96596f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8687535592fb4ceb8d32fc0662689b62",
            "max": 96,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed68588daa134f9f874b689fd04c9416",
            "value": 96
          }
        },
        "70fcea0c0d3049a2a97848fb58b4e4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d8477dcda1f4e32900f571b2cbdba21",
            "max": 4704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a32195f1ee8542ffa955a1e02c18b9dd",
            "value": 4704
          }
        },
        "71502e68d60540fdbb907831e97da3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8477dcda1f4e32900f571b2cbdba21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8687535592fb4ceb8d32fc0662689b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90db3341b7a746a7bf89d868a3bd8ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32195f1ee8542ffa955a1e02c18b9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba32a2d04c044722bd82906fd8bc91c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcea58182a7f4e10a01757a2823a56af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71502e68d60540fdbb907831e97da3ae",
            "placeholder": "​",
            "style": "IPY_MODEL_2219587102284c03b7a17449a9d966d6",
            "value": "Map: 100%"
          }
        },
        "bfb3d2e3668c4b6b8228e4f4c22553d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba32a2d04c044722bd82906fd8bc91c8",
            "placeholder": "​",
            "style": "IPY_MODEL_2d973ad205704896be97f44ca0f97c37",
            "value": " 96/96 [00:00&lt;00:00, 1932.66 examples/s]"
          }
        },
        "e491f00ae2484b9eae62371d70429778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcea58182a7f4e10a01757a2823a56af",
              "IPY_MODEL_49dc357ec52b40b0a99a2a3a96596f83",
              "IPY_MODEL_bfb3d2e3668c4b6b8228e4f4c22553d9"
            ],
            "layout": "IPY_MODEL_f349f1fa77bc44daa5dd3fe8215af87a"
          }
        },
        "e65a444dfc7042f5b55ed3d49fa330ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90db3341b7a746a7bf89d868a3bd8ec9",
            "placeholder": "​",
            "style": "IPY_MODEL_f1aa9386a0d7491597fff62ef721b5bc",
            "value": " 4704/4704 [00:01&lt;00:00, 4087.28 examples/s]"
          }
        },
        "ed68588daa134f9f874b689fd04c9416": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1aa9386a0d7491597fff62ef721b5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f349f1fa77bc44daa5dd3fe8215af87a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
