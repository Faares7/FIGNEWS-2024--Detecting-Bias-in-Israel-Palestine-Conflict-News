{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knKZwzSB_nGS",
        "outputId": "d81cc5c6-bed3-48a8-c800-aa669dd08347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext, langdetect\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498210 sha256=882fc771ed5c4dfcd3f5d0140ac59afb7f64e9cb96500883b6bff57eeaad2d81\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=a70fbe9521f34b076af5b86acb9b73418e9b5cf42efaa125b22893d21b4be6db\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
            "Successfully built fasttext langdetect\n",
            "Installing collected packages: pybind11, langdetect, fasttext\n",
            "Successfully installed fasttext-0.9.3 langdetect-1.0.9 pybind11-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn imbalanced-learn\n",
        "!pip install transformers datasets torch accelerate\n",
        "!pip install fasttext langdetect openpyxl joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "30b47045104a4dfda568bf89e8623c1b",
            "0c400a5df0ed4907bc978fbea62cd598",
            "70fcea0c0d3049a2a97848fb58b4e4e6",
            "e65a444dfc7042f5b55ed3d49fa330ac",
            "02adf9c5ea414d3d844e5b264dad6724",
            "1ce15792fca148eda46e17955389c803",
            "193de67b596e4c57b7c64a3a07824776",
            "7d8477dcda1f4e32900f571b2cbdba21",
            "a32195f1ee8542ffa955a1e02c18b9dd",
            "90db3341b7a746a7bf89d868a3bd8ec9",
            "f1aa9386a0d7491597fff62ef721b5bc",
            "e491f00ae2484b9eae62371d70429778",
            "bcea58182a7f4e10a01757a2823a56af",
            "49dc357ec52b40b0a99a2a3a96596f83",
            "bfb3d2e3668c4b6b8228e4f4c22553d9",
            "f349f1fa77bc44daa5dd3fe8215af87a",
            "71502e68d60540fdbb907831e97da3ae",
            "2219587102284c03b7a17449a9d966d6",
            "8687535592fb4ceb8d32fc0662689b62",
            "ed68588daa134f9f874b689fd04c9416",
            "ba32a2d04c044722bd82906fd8bc91c8",
            "2d973ad205704896be97f44ca0f97c37"
          ]
        },
        "id": "FuvtnPm1-6zk",
        "outputId": "835da965-2b3a-4a45-83b4-f2419cd051a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "✓ Google Drive mounted\n",
            "================================================================================\n",
            "MARBERT ARABIC PIPELINE (Shared Drive + Data Augmentation)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1] Loading and cleaning data...\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/Main.xlsx...\n",
            "    MAIN: 4320 rows\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-1.xlsx...\n",
            "    /content/drive/MyDrive/fignews_shared_project/data/IAA-1.xlsx: 480 rows\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-2.xlsx...\n",
            "    /content/drive/MyDrive/fignews_shared_project/data/IAA-2.xlsx: 480 rows\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-3.xlsx...\n",
            "  Loading /content/drive/MyDrive/fignews_shared_project/data/IAA-4.xlsx...\n",
            "\n",
            "  Total IAA: 960 rows\n",
            "\n",
            "Mapping labels...\n",
            "\n",
            "[STEP 2] Creating train/test splits...\n",
            "\n",
            "  Applying majority vote...\n",
            "\n",
            "  Applying majority vote...\n",
            "\n",
            "  Training: 4704 samples\n",
            "  Test: 96 samples\n",
            "\n",
            "[STEP 3] Preparing Arabic text columns...\n",
            "  Training samples (all rows with Arabic text): 4704\n",
            "  Test samples: 96\n",
            "\n",
            "================================================================================\n",
            "TRAINING MARBERT\n",
            "================================================================================\n",
            "\n",
            "[MARBERT] Initializing...\n",
            "  Model: UBC-NLP/MARBERTv2\n",
            "\n",
            "[STEP 3] Training MARBERTv2...\n",
            "\n",
            "  Class Weights: [0.36981132 1.0929368  7.58709677 4.01365188]\n",
            "\n",
            "  Loading tokenizer and model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERTv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing datasets...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30b47045104a4dfda568bf89e8623c1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4704 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e491f00ae2484b9eae62371d70429778",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/96 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Starting training...\n",
            "    Epochs: 4\n",
            "    Batch size: 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1176' max='1176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1176/1176 08:00, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.316200</td>\n",
              "      <td>1.269186</td>\n",
              "      <td>0.364583</td>\n",
              "      <td>0.240515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.187700</td>\n",
              "      <td>1.047518</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.426971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.967700</td>\n",
              "      <td>1.007246</td>\n",
              "      <td>0.677083</td>\n",
              "      <td>0.499943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.733400</td>\n",
              "      <td>1.077568</td>\n",
              "      <td>0.614583</td>\n",
              "      <td>0.430198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  ✓ Training completed!\n",
            "\n",
            "  Saving best model to shared Drive...\n",
            "  Path: /content/drive/MyDrive/fignews_shared_project/models/marbert_finetuned/\n",
            "\n",
            "  Cleaning up intermediate checkpoints...\n",
            "    Removing checkpoint-882...\n",
            "  ✓ Model saved to shared Drive!\n",
            "\n",
            "[STEP 4] Evaluating MARBERTv2...\n",
            "  Generating predictions...\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT (ARABIC)\n",
            "================================================================================\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "   Biased Against Israel     0.0000    0.0000    0.0000         1\n",
            "Biased Against Palestine     0.6190    0.6500    0.6341        20\n",
            "                  Others     0.5000    0.7500    0.6000         4\n",
            "                Unbiased     0.8596    0.6901    0.7656        71\n",
            "\n",
            "                accuracy                         0.6771        96\n",
            "               macro avg     0.4947    0.5225    0.4999        96\n",
            "            weighted avg     0.7856    0.6771    0.7234        96\n",
            "\n",
            "\n",
            "Accuracy: 0.6771\n",
            "Macro F1: 0.4999\n",
            "\n",
            "================================================================================\n",
            "MARBERT TRAINING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Model saved to shared Drive: /content/drive/MyDrive/fignews_shared_project/models/marbert_finetuned/\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "FIGNEWS-2024: MARBERT ARABIC (TEAM VERSION - SHARED DRIVE)\n",
        "==========================================================\n",
        "- Uses shared Google Drive for storage\n",
        "- Saves best model only (with checkpoint cleanup)\n",
        "- Data logic: Uses Arabic MT if English source, Text if Arabic source\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# GOOGLE DRIVE MOUNT\n",
        "# ============================================================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "print(\"✓ Google Drive mounted\")\n",
        "\n",
        "# ============================================================================\n",
        "# IMPORTS\n",
        "# ============================================================================\n",
        "import os\n",
        "import warnings\n",
        "import re\n",
        "import shutil\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"MARBERT ARABIC PIPELINE (Shared Drive + Data Augmentation)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Pipeline configuration\"\"\"\n",
        "\n",
        "    # ========== SHARED DRIVE PATHS ==========\n",
        "    BASE_PATH = \"/content/drive/MyDrive/fignews_shared_project/\"\n",
        "\n",
        "    # Data paths\n",
        "    MAIN_FILE = BASE_PATH + \"data/Main.xlsx\"\n",
        "    IAA_FILES = [\n",
        "        BASE_PATH + \"data/IAA-1.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-2.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-3.xlsx\",\n",
        "        BASE_PATH + \"data/IAA-4.xlsx\"\n",
        "    ]\n",
        "\n",
        "    # Output directory\n",
        "    OUTPUT_DIR = BASE_PATH + \"models/marbert_finetuned/\"\n",
        "    # =========================================\n",
        "\n",
        "    # Label mapping\n",
        "    LABEL_MAP = {\n",
        "        'Unbiased': 'Unbiased',\n",
        "        'Biased against Palestine': 'Biased Against Palestine',\n",
        "        'Biased Against Palestine': 'Biased Against Palestine',\n",
        "        'Biased against Israel': 'Biased Against Israel',\n",
        "        'Biased Against Israel': 'Biased Against Israel',\n",
        "        'Unclear': 'Others',\n",
        "        'Biased against others': 'Others',\n",
        "        'Biased against both': 'Others',\n",
        "        'Biased against both Palestine and Israel': 'Others',\n",
        "        'Not Applicable': 'Others',\n",
        "        'Others': 'Others'\n",
        "    }\n",
        "\n",
        "    TARGET_LABELS = ['Unbiased', 'Biased Against Palestine',\n",
        "                     'Biased Against Israel', 'Others']\n",
        "    LABEL2ID = {label: idx for idx, label in enumerate(TARGET_LABELS)}\n",
        "    ID2LABEL = {idx: label for label, idx in LABEL2ID.items()}\n",
        "\n",
        "    MODEL_NAME = \"UBC-NLP/MARBERTv2\"\n",
        "    IAA_TRAIN_SPLIT = 0.8\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Training arguments (Save best model)\n",
        "    TRAINING_ARGS = {\n",
        "        \"output_dir\": OUTPUT_DIR,\n",
        "        \"num_train_epochs\": 4,\n",
        "        \"per_device_train_batch_size\": 16,\n",
        "        \"per_device_eval_batch_size\": 16,\n",
        "        \"learning_rate\": 2e-5,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"eval_strategy\": \"epoch\",\n",
        "        \"save_strategy\": \"epoch\",  # Save after each epoch\n",
        "        \"save_total_limit\": 1,  # Keep only best checkpoint\n",
        "        \"load_best_model_at_end\": True,  # Load best model\n",
        "        \"metric_for_best_model\": \"f1_macro\",\n",
        "        \"logging_steps\": 50,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def clean_urls_and_format(text: str) -> str:\n",
        "    \"\"\"Basic cleaning for LLM models.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    text = text.replace(':=:', ' ')\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def filter_languages(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Keep ONLY English and Arabic rows.\"\"\"\n",
        "    mask = df['Source Language'].str.contains('English|Arabic', case=False, na=False)\n",
        "    return df[mask].copy()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING & PREPARATION\n",
        "# ============================================================================\n",
        "\n",
        "def load_and_clean_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load MAIN and IAA files.\"\"\"\n",
        "    print(\"\\n[STEP 1] Loading and cleaning data...\")\n",
        "\n",
        "    if not os.path.exists(Config.MAIN_FILE):\n",
        "        raise FileNotFoundError(f\"{Config.MAIN_FILE} not found!\")\n",
        "\n",
        "    print(f\"  Loading {Config.MAIN_FILE}...\")\n",
        "    main_df = pd.read_excel(Config.MAIN_FILE)\n",
        "\n",
        "    main_df = main_df[main_df['Bias'].notna() & (main_df['Bias'] != '')]\n",
        "    main_df['Bias'] = main_df['Bias'].astype(str).str.strip()\n",
        "    main_df = filter_languages(main_df)\n",
        "\n",
        "    # Clean all text columns\n",
        "    for col in ['Text', 'Arabic MT', 'English MT']:\n",
        "        if col in main_df.columns:\n",
        "            main_df[col] = main_df[col].apply(clean_urls_and_format)\n",
        "\n",
        "    print(f\"    MAIN: {len(main_df)} rows\")\n",
        "\n",
        "    # Load IAA\n",
        "    iaa_dfs = []\n",
        "    for iaa_file in Config.IAA_FILES:\n",
        "        if os.path.exists(iaa_file):\n",
        "            print(f\"  Loading {iaa_file}...\")\n",
        "            iaa_df_temp = pd.read_excel(iaa_file)\n",
        "\n",
        "            if 'Bais' in iaa_df_temp.columns:\n",
        "                iaa_df_temp['Bias'] = iaa_df_temp['Bais']\n",
        "\n",
        "            iaa_df_temp = iaa_df_temp[iaa_df_temp['Bias'].notna() &\n",
        "                                       (iaa_df_temp['Bias'] != '')]\n",
        "            iaa_df_temp['Bias'] = iaa_df_temp['Bias'].astype(str).str.strip()\n",
        "\n",
        "            if len(iaa_df_temp) > 0:\n",
        "                iaa_df_temp = filter_languages(iaa_df_temp)\n",
        "\n",
        "            if len(iaa_df_temp) > 0:\n",
        "                for col in ['Text', 'Arabic MT', 'English MT']:\n",
        "                    if col in iaa_df_temp.columns:\n",
        "                        iaa_df_temp[col] = iaa_df_temp[col].apply(clean_urls_and_format)\n",
        "                iaa_dfs.append(iaa_df_temp)\n",
        "                print(f\"    {iaa_file}: {len(iaa_df_temp)} rows\")\n",
        "\n",
        "    iaa_df = pd.concat(iaa_dfs, ignore_index=True) if iaa_dfs else pd.DataFrame()\n",
        "    print(f\"\\n  Total IAA: {len(iaa_df)} rows\")\n",
        "\n",
        "    return main_df, iaa_df\n",
        "\n",
        "\n",
        "def map_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Map labels to 4-class taxonomy.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['Bias_Mapped'] = df['Bias'].map(Config.LABEL_MAP)\n",
        "    df['Bias_Mapped'] = df['Bias_Mapped'].fillna('Others')\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_majority_vote(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Apply majority voting.\"\"\"\n",
        "    print(\"\\n  Applying majority vote...\")\n",
        "    df['Text_ID'] = df['ID'].astype(str) + \"_\" + df['Text'].str[:20]\n",
        "\n",
        "    gold_rows = []\n",
        "    for text_id, group in df.groupby('Text_ID'):\n",
        "        labels = group['Bias_Mapped'].tolist()\n",
        "        majority_label = Counter(labels).most_common(1)[0][0]\n",
        "\n",
        "        gold_row = group.iloc[0].copy()\n",
        "        gold_row['Bias_Mapped'] = majority_label\n",
        "        gold_rows.append(gold_row)\n",
        "\n",
        "    return pd.DataFrame(gold_rows)\n",
        "\n",
        "\n",
        "def create_train_test_split(main_df: pd.DataFrame,\n",
        "                            iaa_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Create train/test splits.\"\"\"\n",
        "    print(\"\\n[STEP 2] Creating train/test splits...\")\n",
        "\n",
        "    unique_ids = (iaa_df['Text_ID'].unique() if 'Text_ID' in iaa_df.columns\n",
        "                  else iaa_df['ID'].unique())\n",
        "\n",
        "    train_ids, test_ids = train_test_split(\n",
        "        unique_ids,\n",
        "        test_size=(1 - Config.IAA_TRAIN_SPLIT),\n",
        "        random_state=Config.RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    if 'Text_ID' in iaa_df.columns:\n",
        "        iaa_train = iaa_df[iaa_df['Text_ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['Text_ID'].isin(test_ids)].copy()\n",
        "    else:\n",
        "        iaa_train = iaa_df[iaa_df['ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['ID'].isin(test_ids)].copy()\n",
        "\n",
        "    iaa_train_collapsed = apply_majority_vote(iaa_train)\n",
        "    iaa_test_collapsed = apply_majority_vote(iaa_test)\n",
        "\n",
        "    train_df = pd.concat([main_df, iaa_train_collapsed], ignore_index=True)\n",
        "    test_df = iaa_test_collapsed\n",
        "\n",
        "    print(f\"\\n  Training: {len(train_df)} samples\")\n",
        "    print(f\"  Test: {len(test_df)} samples\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "def prepare_arabic_text(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    CRITICAL DATA LOGIC:\n",
        "    - If Source is Arabic → use Text\n",
        "    - If Source is English → use Arabic MT\n",
        "    This maximizes Arabic training data.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    df['ModelText'] = df.apply(\n",
        "        lambda row: row['Arabic MT'] if 'English' in str(row.get('Source Language', ''))\n",
        "                   else row['Text'],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# WEIGHTED TRAINER\n",
        "# ============================================================================\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Custom Trainer with weighted cross-entropy loss.\"\"\"\n",
        "\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        \"\"\"Compute weighted loss.\"\"\"\n",
        "        if self.class_weights.device != model.device:\n",
        "            self.class_weights = self.class_weights.to(model.device)\n",
        "\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1_macro\n",
        "    }\n",
        "\n",
        "\n",
        "def prepare_dataset(df: pd.DataFrame, tokenizer, text_column: str = 'ModelText'):\n",
        "    \"\"\"Prepare dataset for transformer training.\"\"\"\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=128\n",
        "        )\n",
        "\n",
        "    data_dict = {\n",
        "        'text': df[text_column].tolist(),\n",
        "        'label': df['Bias_Mapped'].map(Config.LABEL2ID).tolist()\n",
        "    }\n",
        "\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MARBERT MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class MARBERTModel:\n",
        "    \"\"\"MARBERTv2 model wrapper.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        print(f\"\\n[MARBERT] Initializing...\")\n",
        "        print(f\"  Model: {Config.MODEL_NAME}\")\n",
        "\n",
        "    def train(self, train_df: pd.DataFrame, eval_df: pd.DataFrame = None):\n",
        "        \"\"\"Train MARBERTv2 with weighted loss.\"\"\"\n",
        "        print(\"\\n[STEP 3] Training MARBERTv2...\")\n",
        "\n",
        "        # Calculate class weights\n",
        "        labels = train_df['Bias_Mapped'].map(Config.LABEL2ID).values\n",
        "        class_weights = compute_class_weight('balanced',\n",
        "                                             classes=np.unique(labels),\n",
        "                                             y=labels)\n",
        "\n",
        "        full_weights = np.ones(len(Config.TARGET_LABELS))\n",
        "        for cls_idx, weight in zip(np.unique(labels), class_weights):\n",
        "            full_weights[cls_idx] = weight\n",
        "\n",
        "        print(f\"\\n  Class Weights: {full_weights}\")\n",
        "\n",
        "        # Load tokenizer and model\n",
        "        print(f\"\\n  Loading tokenizer and model...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            Config.MODEL_NAME,\n",
        "            num_labels=len(Config.TARGET_LABELS),\n",
        "            id2label=Config.ID2LABEL,\n",
        "            label2id=Config.LABEL2ID\n",
        "        )\n",
        "\n",
        "        # Prepare datasets\n",
        "        print(\"  Preparing datasets...\")\n",
        "        train_dataset = prepare_dataset(train_df, self.tokenizer)\n",
        "        eval_dataset = None\n",
        "        if eval_df is not None and len(eval_df) > 0:\n",
        "            eval_dataset = prepare_dataset(eval_df, self.tokenizer)\n",
        "\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            **Config.TRAINING_ARGS,\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        # Weighted Trainer\n",
        "        self.trainer = WeightedTrainer(\n",
        "            class_weights=full_weights,\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] if eval_dataset else None\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        print(\"\\n  Starting training...\")\n",
        "        print(f\"    Epochs: {Config.TRAINING_ARGS['num_train_epochs']}\")\n",
        "        print(f\"    Batch size: {Config.TRAINING_ARGS['per_device_train_batch_size']}\")\n",
        "\n",
        "        self.trainer.train()\n",
        "\n",
        "        print(\"\\n  ✓ Training completed!\")\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[str]:\n",
        "        \"\"\"Predict labels for texts.\"\"\"\n",
        "        if not texts:\n",
        "            return []\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return [Config.ID2LABEL[pred.item()] for pred in predictions]\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save best model and clean up checkpoints.\"\"\"\n",
        "        os.makedirs(Config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n  Saving best model to shared Drive...\")\n",
        "        print(f\"  Path: {Config.OUTPUT_DIR}\")\n",
        "\n",
        "        # Best model is already loaded (load_best_model_at_end=True)\n",
        "        self.model.save_pretrained(Config.OUTPUT_DIR)\n",
        "        self.tokenizer.save_pretrained(Config.OUTPUT_DIR)\n",
        "\n",
        "        # Save training metadata\n",
        "        import json\n",
        "        metadata = {\n",
        "            \"model_name\": Config.MODEL_NAME,\n",
        "            \"training_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"num_epochs\": Config.TRAINING_ARGS[\"num_train_epochs\"],\n",
        "            \"batch_size\": Config.TRAINING_ARGS[\"per_device_train_batch_size\"],\n",
        "            \"learning_rate\": Config.TRAINING_ARGS[\"learning_rate\"],\n",
        "            \"data_strategy\": \"Uses Arabic MT if source is English, Text if source is Arabic\",\n",
        "            \"note\": \"Best model only (intermediate checkpoints removed)\"\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(Config.OUTPUT_DIR, \"training_info.json\"), \"w\") as f:\n",
        "            json.dump(metadata, f, indent=2)\n",
        "\n",
        "        # Clean up checkpoint folders\n",
        "        print(\"\\n  Cleaning up intermediate checkpoints...\")\n",
        "        for item in os.listdir(Config.OUTPUT_DIR):\n",
        "            item_path = os.path.join(Config.OUTPUT_DIR, item)\n",
        "            if os.path.isdir(item_path) and item.startswith('checkpoint-'):\n",
        "                print(f\"    Removing {item}...\")\n",
        "                shutil.rmtree(item_path)\n",
        "\n",
        "        print(f\"  ✓ Model saved to shared Drive!\")\n",
        "\n",
        "    def evaluate(self, test_df: pd.DataFrame):\n",
        "        \"\"\"Evaluate model on test set.\"\"\"\n",
        "        print(\"\\n[STEP 4] Evaluating MARBERTv2...\")\n",
        "\n",
        "        texts = test_df['ModelText'].tolist()\n",
        "        true_labels = test_df['Bias_Mapped'].tolist()\n",
        "\n",
        "        print(\"  Generating predictions...\")\n",
        "        predictions = self.predict(texts)\n",
        "\n",
        "        # Get unique labels in test set\n",
        "        unique_labels = sorted(set(true_labels))\n",
        "        present_label_names = [Config.TARGET_LABELS[Config.LABEL2ID[label]]\n",
        "                               for label in unique_labels]\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLASSIFICATION REPORT (ARABIC)\")\n",
        "        print(\"=\"*80)\n",
        "        print(classification_report(\n",
        "            true_labels,\n",
        "            predictions,\n",
        "            labels=unique_labels,\n",
        "            target_names=present_label_names,\n",
        "            digits=4,\n",
        "            zero_division=0\n",
        "        ))\n",
        "\n",
        "        acc = accuracy_score(true_labels, predictions)\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "\n",
        "        print(f\"\\nAccuracy: {acc:.4f}\")\n",
        "        print(f\"Macro F1: {f1_macro:.4f}\")\n",
        "\n",
        "        return predictions, acc, f1_macro\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training pipeline.\"\"\"\n",
        "\n",
        "    # Set random seeds\n",
        "    np.random.seed(Config.RANDOM_STATE)\n",
        "    torch.manual_seed(Config.RANDOM_STATE)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(Config.RANDOM_STATE)\n",
        "\n",
        "    # Load data\n",
        "    main_df, iaa_df = load_and_clean_data()\n",
        "\n",
        "    # Map labels\n",
        "    print(\"\\nMapping labels...\")\n",
        "    main_df = map_labels(main_df)\n",
        "    iaa_df = map_labels(iaa_df) if len(iaa_df) > 0 else iaa_df\n",
        "\n",
        "    # Create splits\n",
        "    train_df, test_df = create_train_test_split(main_df, iaa_df)\n",
        "\n",
        "    # Prepare Arabic text (use Arabic MT for English sources)\n",
        "    print(\"\\n[STEP 3] Preparing Arabic text columns...\")\n",
        "    train_ar = prepare_arabic_text(train_df)\n",
        "    test_ar = prepare_arabic_text(test_df)\n",
        "\n",
        "    print(f\"  Training samples (all rows with Arabic text): {len(train_ar)}\")\n",
        "    print(f\"  Test samples: {len(test_ar)}\")\n",
        "\n",
        "    if len(train_ar) == 0:\n",
        "        print(\"\\n  ERROR: No training data found!\")\n",
        "        return\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TRAINING MARBERT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    model = MARBERTModel()\n",
        "    eval_ar = test_ar if len(test_ar) > 0 else None\n",
        "    model.train(train_ar, eval_ar)\n",
        "\n",
        "    # Save model\n",
        "    model.save()\n",
        "\n",
        "    # Evaluate\n",
        "    if len(test_ar) > 0:\n",
        "        model.evaluate(test_ar)\n",
        "    else:\n",
        "        print(\"\\n  Warning: No test data for evaluation\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MARBERT TRAINING COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\nModel saved to shared Drive: {Config.OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02adf9c5ea414d3d844e5b264dad6724": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c400a5df0ed4907bc978fbea62cd598": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce15792fca148eda46e17955389c803",
            "placeholder": "​",
            "style": "IPY_MODEL_193de67b596e4c57b7c64a3a07824776",
            "value": "Map: 100%"
          }
        },
        "193de67b596e4c57b7c64a3a07824776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce15792fca148eda46e17955389c803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2219587102284c03b7a17449a9d966d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d973ad205704896be97f44ca0f97c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b47045104a4dfda568bf89e8623c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c400a5df0ed4907bc978fbea62cd598",
              "IPY_MODEL_70fcea0c0d3049a2a97848fb58b4e4e6",
              "IPY_MODEL_e65a444dfc7042f5b55ed3d49fa330ac"
            ],
            "layout": "IPY_MODEL_02adf9c5ea414d3d844e5b264dad6724"
          }
        },
        "49dc357ec52b40b0a99a2a3a96596f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8687535592fb4ceb8d32fc0662689b62",
            "max": 96,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed68588daa134f9f874b689fd04c9416",
            "value": 96
          }
        },
        "70fcea0c0d3049a2a97848fb58b4e4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d8477dcda1f4e32900f571b2cbdba21",
            "max": 4704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a32195f1ee8542ffa955a1e02c18b9dd",
            "value": 4704
          }
        },
        "71502e68d60540fdbb907831e97da3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8477dcda1f4e32900f571b2cbdba21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8687535592fb4ceb8d32fc0662689b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90db3341b7a746a7bf89d868a3bd8ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32195f1ee8542ffa955a1e02c18b9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba32a2d04c044722bd82906fd8bc91c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcea58182a7f4e10a01757a2823a56af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71502e68d60540fdbb907831e97da3ae",
            "placeholder": "​",
            "style": "IPY_MODEL_2219587102284c03b7a17449a9d966d6",
            "value": "Map: 100%"
          }
        },
        "bfb3d2e3668c4b6b8228e4f4c22553d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba32a2d04c044722bd82906fd8bc91c8",
            "placeholder": "​",
            "style": "IPY_MODEL_2d973ad205704896be97f44ca0f97c37",
            "value": " 96/96 [00:00&lt;00:00, 1932.66 examples/s]"
          }
        },
        "e491f00ae2484b9eae62371d70429778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcea58182a7f4e10a01757a2823a56af",
              "IPY_MODEL_49dc357ec52b40b0a99a2a3a96596f83",
              "IPY_MODEL_bfb3d2e3668c4b6b8228e4f4c22553d9"
            ],
            "layout": "IPY_MODEL_f349f1fa77bc44daa5dd3fe8215af87a"
          }
        },
        "e65a444dfc7042f5b55ed3d49fa330ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90db3341b7a746a7bf89d868a3bd8ec9",
            "placeholder": "​",
            "style": "IPY_MODEL_f1aa9386a0d7491597fff62ef721b5bc",
            "value": " 4704/4704 [00:01&lt;00:00, 4087.28 examples/s]"
          }
        },
        "ed68588daa134f9f874b689fd04c9416": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1aa9386a0d7491597fff62ef721b5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f349f1fa77bc44daa5dd3fe8215af87a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
