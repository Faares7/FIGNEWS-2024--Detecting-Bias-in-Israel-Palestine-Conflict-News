{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dfbb1c351fc4ceaa4e4f83bfefcb0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c73ffedcaf44ce7b1b353652008552f",
              "IPY_MODEL_90663b025c4b48559c33ccba7fc070eb",
              "IPY_MODEL_467d32b689ce4bdb9a67e80c00503308"
            ],
            "layout": "IPY_MODEL_c8576b16422444828d1b23b95227e947"
          }
        },
        "4c73ffedcaf44ce7b1b353652008552f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83103ceb9aa4469e88eeababc66eeb1c",
            "placeholder": "​",
            "style": "IPY_MODEL_432f304d79814eb69e9ed1334626adf4",
            "value": "Map: 100%"
          }
        },
        "90663b025c4b48559c33ccba7fc070eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe8258929704265a94bb506c1fbbb8e",
            "max": 11760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26a36fb082c04728a6d346df18a3784b",
            "value": 11760
          }
        },
        "467d32b689ce4bdb9a67e80c00503308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab6e60f8a5d49bca7b1d1fab849bb2a",
            "placeholder": "​",
            "style": "IPY_MODEL_9ee8862e93d44a9cb8a9f0c6a18e9635",
            "value": " 11760/11760 [00:06&lt;00:00, 2188.89 examples/s]"
          }
        },
        "c8576b16422444828d1b23b95227e947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83103ceb9aa4469e88eeababc66eeb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432f304d79814eb69e9ed1334626adf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fe8258929704265a94bb506c1fbbb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a36fb082c04728a6d346df18a3784b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab6e60f8a5d49bca7b1d1fab849bb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee8862e93d44a9cb8a9f0c6a18e9635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1de81ee0abf4db29263c2251a60b2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18a15918ecb444849aa73469bd3fa3aa",
              "IPY_MODEL_324e308d35044e9495e98042433b8808",
              "IPY_MODEL_dcbf969695294fd48994a4c38019a47e"
            ],
            "layout": "IPY_MODEL_b89051db3ae145bfa927fba4d55ea05c"
          }
        },
        "18a15918ecb444849aa73469bd3fa3aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47e13edb276c44c197262d89888168d6",
            "placeholder": "​",
            "style": "IPY_MODEL_7c5d4a3d5b6b4962a20324d2438f97ed",
            "value": "Map: 100%"
          }
        },
        "324e308d35044e9495e98042433b8808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_341872b799444034a2a7378084645c90",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8624a345235a4c11ac8a69c76ff2f3ac",
            "value": 240
          }
        },
        "dcbf969695294fd48994a4c38019a47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ecface96ec04c0984c9fa4e70579a5b",
            "placeholder": "​",
            "style": "IPY_MODEL_59c97d2b943a480aa7e7fd856675e49e",
            "value": " 240/240 [00:00&lt;00:00, 1888.85 examples/s]"
          }
        },
        "b89051db3ae145bfa927fba4d55ea05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e13edb276c44c197262d89888168d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5d4a3d5b6b4962a20324d2438f97ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341872b799444034a2a7378084645c90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8624a345235a4c11ac8a69c76ff2f3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ecface96ec04c0984c9fa4e70579a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c97d2b943a480aa7e7fd856675e49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6201d5b89ade4620840d10c81ec9d159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00821ec2761d42feaf1253570fefd03c",
              "IPY_MODEL_372dc74c92ca4962bb2730a39fac5a1d",
              "IPY_MODEL_8cbf4d816e6b47bdb12501bdb3fc61d9"
            ],
            "layout": "IPY_MODEL_a466652db2714a6891cea185e9f2db24"
          }
        },
        "00821ec2761d42feaf1253570fefd03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bd489ec5c854fb883b3acf1bc9d9622",
            "placeholder": "​",
            "style": "IPY_MODEL_4d280e3637dc4532805984db18f22563",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "372dc74c92ca4962bb2730a39fac5a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_918e8155e19c4826bb9a2e84356bf493",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcab08aa58834a5b8a737cd8221db9da",
            "value": 25
          }
        },
        "8cbf4d816e6b47bdb12501bdb3fc61d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5905281e060455fa0ee5546b85c91c8",
            "placeholder": "​",
            "style": "IPY_MODEL_9fadbec210c94985b1d3049ee2262b36",
            "value": " 25.0/25.0 [00:00&lt;00:00, 849B/s]"
          }
        },
        "a466652db2714a6891cea185e9f2db24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bd489ec5c854fb883b3acf1bc9d9622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d280e3637dc4532805984db18f22563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "918e8155e19c4826bb9a2e84356bf493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcab08aa58834a5b8a737cd8221db9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5905281e060455fa0ee5546b85c91c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fadbec210c94985b1d3049ee2262b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68a762f1bf0b48d6bd6e530be0032969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc924f1bbd5e4ad4b089f64be4234317",
              "IPY_MODEL_664a073208ae45de8460e2ab42115472",
              "IPY_MODEL_3a7ba8bb62114b85b4b822678b39e33e"
            ],
            "layout": "IPY_MODEL_0fd5452486a74ab59f7c6c7fabe7b571"
          }
        },
        "cc924f1bbd5e4ad4b089f64be4234317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a4a51db52c471a96913c4fa9904e47",
            "placeholder": "​",
            "style": "IPY_MODEL_325d42af097d4081ab3707347274774f",
            "value": "config.json: 100%"
          }
        },
        "664a073208ae45de8460e2ab42115472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6870f559335c43ce88d1685bb6132916",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09b87a5bccd64137850ad8f9eb911734",
            "value": 615
          }
        },
        "3a7ba8bb62114b85b4b822678b39e33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3070839325474d019add996003987c9a",
            "placeholder": "​",
            "style": "IPY_MODEL_79d75c196df746eb9df496bb5cbf87eb",
            "value": " 615/615 [00:00&lt;00:00, 16.6kB/s]"
          }
        },
        "0fd5452486a74ab59f7c6c7fabe7b571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a4a51db52c471a96913c4fa9904e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "325d42af097d4081ab3707347274774f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6870f559335c43ce88d1685bb6132916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b87a5bccd64137850ad8f9eb911734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3070839325474d019add996003987c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d75c196df746eb9df496bb5cbf87eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea8f9dd234194647b44587a0db4e7e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_551b391ed08541ea93106502880d8e87",
              "IPY_MODEL_0f40ac37688947bea4b49aba6dce3d2a",
              "IPY_MODEL_c399173fdd0a4c9493dc4a42ec1f3d0c"
            ],
            "layout": "IPY_MODEL_ba1b650f9a2f47faae7ef2ccea56cb93"
          }
        },
        "551b391ed08541ea93106502880d8e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4482917ad5e447c595b95eb84147009e",
            "placeholder": "​",
            "style": "IPY_MODEL_f8ccddfaa6074278add0b0e09c219d1f",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "0f40ac37688947bea4b49aba6dce3d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e67d83347954cf1b9fc0ea33727a53e",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78a858aef135465b8de945bd7cf3d1de",
            "value": 5069051
          }
        },
        "c399173fdd0a4c9493dc4a42ec1f3d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e05e8a90e24e01a5f145a03314f856",
            "placeholder": "​",
            "style": "IPY_MODEL_65c2dff6c3db48a6a10ad26b94922e5b",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 20.0MB/s]"
          }
        },
        "ba1b650f9a2f47faae7ef2ccea56cb93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4482917ad5e447c595b95eb84147009e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ccddfaa6074278add0b0e09c219d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e67d83347954cf1b9fc0ea33727a53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a858aef135465b8de945bd7cf3d1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0e05e8a90e24e01a5f145a03314f856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c2dff6c3db48a6a10ad26b94922e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b36aaeb2f44040c0bab31d757033d078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29c6c4db5c6c454c8b4f79e5e2f3f50a",
              "IPY_MODEL_c0ccb7e3cc2d4396bc93dfc1772eda2c",
              "IPY_MODEL_db74f02c28c34b80bbf23eda30bea4e6"
            ],
            "layout": "IPY_MODEL_74a63cb9756d4576908dc3484eccb2fc"
          }
        },
        "29c6c4db5c6c454c8b4f79e5e2f3f50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744744c1c7fb44d2b8eab48fcc96ef16",
            "placeholder": "​",
            "style": "IPY_MODEL_0e9f06dc701145908b15b6a243c4d517",
            "value": "tokenizer.json: 100%"
          }
        },
        "c0ccb7e3cc2d4396bc93dfc1772eda2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ac82ce0e89472cb7864957fff63515",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4cfd0fcf1ad4b5abab3d6b5ec9365c0",
            "value": 9096718
          }
        },
        "db74f02c28c34b80bbf23eda30bea4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c17f95c38343c9ba9167b026a5b689",
            "placeholder": "​",
            "style": "IPY_MODEL_8e3f6d05a9d54f82aa6ee5f21804d5a3",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 21.2MB/s]"
          }
        },
        "74a63cb9756d4576908dc3484eccb2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744744c1c7fb44d2b8eab48fcc96ef16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9f06dc701145908b15b6a243c4d517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08ac82ce0e89472cb7864957fff63515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cfd0fcf1ad4b5abab3d6b5ec9365c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6c17f95c38343c9ba9167b026a5b689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e3f6d05a9d54f82aa6ee5f21804d5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e4a3c7019449b29286b0aa86e65c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2666f535203a478883d79c54336a5d11",
              "IPY_MODEL_ada110df58744a37a370e621e40853cc",
              "IPY_MODEL_ca9fce0249db4319962c351da9fe997f"
            ],
            "layout": "IPY_MODEL_eccf30f7c29a42d8bd76c3682eb27ce4"
          }
        },
        "2666f535203a478883d79c54336a5d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21d687ee8384df0849523b8569057d8",
            "placeholder": "​",
            "style": "IPY_MODEL_77962a19886943cb90856fcb8fd10158",
            "value": "model.safetensors: 100%"
          }
        },
        "ada110df58744a37a370e621e40853cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d5622ca5144830b6705786d261ed5c",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdddfd1ce051444783059609d55a256a",
            "value": 1115567652
          }
        },
        "ca9fce0249db4319962c351da9fe997f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_565aa18712fc44629bf9ee0e3c7f01ef",
            "placeholder": "​",
            "style": "IPY_MODEL_cc85671e596f40b0b296d1d5b6019435",
            "value": " 1.12G/1.12G [00:10&lt;00:00, 193MB/s]"
          }
        },
        "eccf30f7c29a42d8bd76c3682eb27ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21d687ee8384df0849523b8569057d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77962a19886943cb90856fcb8fd10158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d5622ca5144830b6705786d261ed5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdddfd1ce051444783059609d55a256a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "565aa18712fc44629bf9ee0e3c7f01ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc85671e596f40b0b296d1d5b6019435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e05b0ffaa9274be8ac4f751798b167e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a34c4471ba74ed19fcb1ec0f81584dc",
              "IPY_MODEL_5e931e839d004e0c96a6c1d9387505b2",
              "IPY_MODEL_a6bed40ce803401bb5337a76977a224f"
            ],
            "layout": "IPY_MODEL_eb16c796687e431b9fdc4b2aa2fbd5d6"
          }
        },
        "6a34c4471ba74ed19fcb1ec0f81584dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e2647f51374b8f9872328de7c50929",
            "placeholder": "​",
            "style": "IPY_MODEL_4cbe4c7449db499ab190d45f0b7c37fc",
            "value": "Map: 100%"
          }
        },
        "5e931e839d004e0c96a6c1d9387505b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ad5b6e61b04d50b4a1d00f507b7d66",
            "max": 11760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d2ac11c0cb42d28b6bbd8c98789784",
            "value": 11760
          }
        },
        "a6bed40ce803401bb5337a76977a224f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828c8fb98bdd4ae9a852c64d80ab2c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_d2d7695acd4c4ec688142c21fd5075a1",
            "value": " 11760/11760 [00:12&lt;00:00, 1116.67 examples/s]"
          }
        },
        "eb16c796687e431b9fdc4b2aa2fbd5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e2647f51374b8f9872328de7c50929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbe4c7449db499ab190d45f0b7c37fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ad5b6e61b04d50b4a1d00f507b7d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d2ac11c0cb42d28b6bbd8c98789784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "828c8fb98bdd4ae9a852c64d80ab2c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d7695acd4c4ec688142c21fd5075a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2b85ce638c74b7da05d1e74d996b139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed6bcfab5d05415fb497e900108e6523",
              "IPY_MODEL_07026c75f2be45c19f435c04bf1fb7f6",
              "IPY_MODEL_3392509065cd436cae6925d70de1b641"
            ],
            "layout": "IPY_MODEL_d379b8d16ebe4f54b7c7de31b717176c"
          }
        },
        "ed6bcfab5d05415fb497e900108e6523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f87e99f6f0c847debbe5e7d5d686be3a",
            "placeholder": "​",
            "style": "IPY_MODEL_e50342ceb3664434a2ef2e5b479cbe04",
            "value": "Map: 100%"
          }
        },
        "07026c75f2be45c19f435c04bf1fb7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72930583813d4eba92aa6b502ba573c6",
            "max": 240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d4ef962ae67461fb8a1297de0b8b05f",
            "value": 240
          }
        },
        "3392509065cd436cae6925d70de1b641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9946c300023c4a5aaa757dd83f8edca0",
            "placeholder": "​",
            "style": "IPY_MODEL_1c12b4476be34fd28a43c6ded083e923",
            "value": " 240/240 [00:00&lt;00:00, 1038.92 examples/s]"
          }
        },
        "d379b8d16ebe4f54b7c7de31b717176c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87e99f6f0c847debbe5e7d5d686be3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e50342ceb3664434a2ef2e5b479cbe04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72930583813d4eba92aa6b502ba573c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4ef962ae67461fb8a1297de0b8b05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9946c300023c4a5aaa757dd83f8edca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c12b4476be34fd28a43c6ded083e923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "637e0fa9cadf45b0af7ec01d2ed41654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36622c2a65d7414ca94d1bf53a12f2ab",
              "IPY_MODEL_88976e54a7b043f19babc96f0be021a6",
              "IPY_MODEL_4cadeda8d5ef480a8a30c487971101ed"
            ],
            "layout": "IPY_MODEL_d65f7d15d9994e61890c2dda9fd43e48"
          }
        },
        "36622c2a65d7414ca94d1bf53a12f2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e74e977a73442eeb71142c461d1dda7",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f2c423ffcc471aaf6ffe31e97e66f6",
            "value": "Map: 100%"
          }
        },
        "88976e54a7b043f19babc96f0be021a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a07b5f7f01c4488bbd294630fe313e8",
            "max": 23520,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2f5e36ec6534ef6b99623255366ed10",
            "value": 23520
          }
        },
        "4cadeda8d5ef480a8a30c487971101ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12cba7a6dcb94f0092f7f68ff17c9960",
            "placeholder": "​",
            "style": "IPY_MODEL_54108fab92d747a8b90a9ef7887d67e3",
            "value": " 23520/23520 [00:13&lt;00:00, 1890.11 examples/s]"
          }
        },
        "d65f7d15d9994e61890c2dda9fd43e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e74e977a73442eeb71142c461d1dda7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f2c423ffcc471aaf6ffe31e97e66f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a07b5f7f01c4488bbd294630fe313e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f5e36ec6534ef6b99623255366ed10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12cba7a6dcb94f0092f7f68ff17c9960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54108fab92d747a8b90a9ef7887d67e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "312e4672649d4995b9d7bc264f9eec9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6f5f8ad6a34451eb18b3219aa54e6e6",
              "IPY_MODEL_80c471a2ff964acc821523adc50cb204",
              "IPY_MODEL_cb5f7d7ad9f3453e9d4bcb4f04bf254c"
            ],
            "layout": "IPY_MODEL_e98a7d7deb9141f39c6d5dc730d1128e"
          }
        },
        "e6f5f8ad6a34451eb18b3219aa54e6e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138eee1378c442178a6bd767abfcce4a",
            "placeholder": "​",
            "style": "IPY_MODEL_592ba0024ee848608405ae468ab0e4a0",
            "value": "Map: 100%"
          }
        },
        "80c471a2ff964acc821523adc50cb204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5d0e352c0f49e98cb3cd0b967b61cc",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c3b2bd848da431f9c3606aeb35d9afe",
            "value": 480
          }
        },
        "cb5f7d7ad9f3453e9d4bcb4f04bf254c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efc3e9cd736847f7903645e3b9fa807c",
            "placeholder": "​",
            "style": "IPY_MODEL_e03cb979cdab4761a3eb9ae2c7fe4778",
            "value": " 480/480 [00:00&lt;00:00, 2006.35 examples/s]"
          }
        },
        "e98a7d7deb9141f39c6d5dc730d1128e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138eee1378c442178a6bd767abfcce4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592ba0024ee848608405ae468ab0e4a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d5d0e352c0f49e98cb3cd0b967b61cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3b2bd848da431f9c3606aeb35d9afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efc3e9cd736847f7903645e3b9fa807c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e03cb979cdab4761a3eb9ae2c7fe4778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX47EvzCDkB4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7dfbb1c351fc4ceaa4e4f83bfefcb0f5",
            "4c73ffedcaf44ce7b1b353652008552f",
            "90663b025c4b48559c33ccba7fc070eb",
            "467d32b689ce4bdb9a67e80c00503308",
            "c8576b16422444828d1b23b95227e947",
            "83103ceb9aa4469e88eeababc66eeb1c",
            "432f304d79814eb69e9ed1334626adf4",
            "0fe8258929704265a94bb506c1fbbb8e",
            "26a36fb082c04728a6d346df18a3784b",
            "5ab6e60f8a5d49bca7b1d1fab849bb2a",
            "9ee8862e93d44a9cb8a9f0c6a18e9635",
            "c1de81ee0abf4db29263c2251a60b2e1",
            "18a15918ecb444849aa73469bd3fa3aa",
            "324e308d35044e9495e98042433b8808",
            "dcbf969695294fd48994a4c38019a47e",
            "b89051db3ae145bfa927fba4d55ea05c",
            "47e13edb276c44c197262d89888168d6",
            "7c5d4a3d5b6b4962a20324d2438f97ed",
            "341872b799444034a2a7378084645c90",
            "8624a345235a4c11ac8a69c76ff2f3ac",
            "0ecface96ec04c0984c9fa4e70579a5b",
            "59c97d2b943a480aa7e7fd856675e49e"
          ]
        },
        "outputId": "633f8a2e-0b54-44d0-8283-2fd74316328b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "XLM-ROBERTA STANDALONE TESTING\n",
            "================================================================================\n",
            "\n",
            "[STEP 1] Loading and cleaning data...\n",
            "  Loading /content/Main.xlsx...\n",
            "    MAIN: 13500 rows → 10800 rows (removed 2700 with missing labels)\n",
            "  Loading /content/IAA-1.xlsx...\n",
            "    /content/IAA-1.xlsx: 1200 rows → 1200 rows\n",
            "  Loading /content/IAA-2.xlsx...\n",
            "    /content/IAA-2.xlsx: 1200 rows → 1200 rows\n",
            "  Loading /content/IAA-3.xlsx...\n",
            "    /content/IAA-3.xlsx: No valid labels found, skipping.\n",
            "  Loading /content/IAA-4.xlsx...\n",
            "    /content/IAA-4.xlsx: No valid labels found, skipping.\n",
            "\n",
            "  Total IAA data: 2400 rows with valid labels\n",
            "\n",
            "[PREPROCESSING] Mapping labels...\n",
            "  Warning: Unmapped labels found: ['Biased against both Palestine and Israel' 'Not Applicable']\n",
            "  Mapping these to 'Others'\n",
            "  Warning: Unmapped labels found: ['Biased against both Palestine and Israel' 'Not Applicable']\n",
            "  Mapping these to 'Others'\n",
            "\n",
            "[STEP 2] Creating train/test splits...\n",
            "  Total unique IAA texts: 1115\n",
            "  IAA split: 892 train IDs, 223 test IDs\n",
            "\n",
            "  Applying majority vote to collapse duplicate annotations...\n",
            "    Collapsed 1920 annotations → 960 unique texts\n",
            "\n",
            "  Applying majority vote to collapse duplicate annotations...\n",
            "    Collapsed 480 annotations → 240 unique texts\n",
            "\n",
            "  Final training set: 11760 samples\n",
            "    - From MAIN (silver): 10800\n",
            "    - From IAA (gold): 960\n",
            "  Final test set: 240 samples (gold standard)\n",
            "\n",
            "  Training set class distribution:\n",
            "Bias_Mapped\n",
            "Unbiased                    7425\n",
            "Biased Against Palestine    3169\n",
            "Others                       871\n",
            "Biased Against Israel        295\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Test set class distribution:\n",
            "Bias_Mapped\n",
            "Unbiased                    157\n",
            "Biased Against Palestine     62\n",
            "Others                       15\n",
            "Biased Against Israel         6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[MODEL] Initializing XLM-RoBERTa Bias Detector\n",
            "  Model: xlm-roberta-base\n",
            "\n",
            "[STEP 3] Training XLM-RoBERTa...\n",
            "  Loading tokenizer and model: xlm-roberta-base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dfbb1c351fc4ceaa4e4f83bfefcb0f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1de81ee0abf4db29263c2251a60b2e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Starting training...\n",
            "    Epochs: 4\n",
            "    Batch size: 16\n",
            "    Learning rate: 2e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2940' max='2940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2940/2940 1:17:39, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.869000</td>\n",
              "      <td>0.814113</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.274308</td>\n",
              "      <td>0.604678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.868100</td>\n",
              "      <td>0.794993</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.309100</td>\n",
              "      <td>0.635633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.848200</td>\n",
              "      <td>0.731510</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.378181</td>\n",
              "      <td>0.695256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.759400</td>\n",
              "      <td>0.706352</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.394129</td>\n",
              "      <td>0.712648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ✓ Training completed successfully!\n",
            "\n",
            "[STEP 4] Evaluating XLM-RoBERTa...\n",
            "  Generating predictions...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-113002651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;31m# Run main pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# Test with examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-113002651.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;31m# Evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n  Warning: No test data available for evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-113002651.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, test_df)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Generating predictions...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;31m# Overall metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-113002651.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1184\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2542\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but got index is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__index_select)"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "XLM-RoBERTa Standalone Testing for FIGNEWS-2024\n",
        "================================================\n",
        "Isolated script to test xlm-roberta-base on bias detection task.\n",
        "This allows quick experimentation without running the full ensemble pipeline.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Core ML libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"XLM-ROBERTA STANDALONE TESTING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration for XLM-RoBERTa testing\"\"\"\n",
        "\n",
        "    # File paths\n",
        "    MAIN_FILE = \"/content/Main.xlsx\"\n",
        "    IAA_FILES = [\"/content/IAA-1.xlsx\", \"/content/IAA-2.xlsx\", \"/content/IAA-3.xlsx\", \"/content/IAA-4.xlsx\"]\n",
        "\n",
        "    # Label mapping\n",
        "    LABEL_MAP = {\n",
        "        'Unbiased': 'Unbiased',\n",
        "        'Biased against Palestine': 'Biased Against Palestine',\n",
        "        'Biased Against Palestine': 'Biased Against Palestine',\n",
        "        'Biased against Israel': 'Biased Against Israel',\n",
        "        'Biased Against Israel': 'Biased Against Israel',\n",
        "        'Unclear': 'Others',\n",
        "        'Biased against others': 'Others',\n",
        "        'Biased against both': 'Others',\n",
        "        'Others': 'Others'\n",
        "    }\n",
        "\n",
        "    TARGET_LABELS = ['Unbiased', 'Biased Against Palestine', 'Biased Against Israel', 'Others']\n",
        "    LABEL2ID = {label: idx for idx, label in enumerate(TARGET_LABELS)}\n",
        "    ID2LABEL = {idx: label for label, idx in LABEL2ID.items()}\n",
        "\n",
        "    # Model configuration\n",
        "    MODEL_NAME = \"xlm-roberta-base\"\n",
        "\n",
        "    # Training parameters\n",
        "    IAA_TRAIN_SPLIT = 0.8\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Training arguments\n",
        "    TRAINING_ARGS = {\n",
        "        \"output_dir\": \"./results_xlm_roberta\",\n",
        "        \"num_train_epochs\": 4,\n",
        "        \"per_device_train_batch_size\": 16,\n",
        "        \"per_device_eval_batch_size\": 16,\n",
        "        \"learning_rate\": 2e-5,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"eval_strategy\": \"epoch\",  # Changed from evaluation_strategy\n",
        "        \"save_strategy\": \"epoch\",\n",
        "        \"load_best_model_at_end\": True,\n",
        "        \"metric_for_best_model\": \"f1_macro\",\n",
        "        \"logging_steps\": 50,\n",
        "        \"warmup_steps\": 100,\n",
        "        \"save_total_limit\": 2,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING & PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def load_and_clean_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load MAIN and IAA files, filter out rows with missing Bias labels.\"\"\"\n",
        "    print(\"\\n[STEP 1] Loading and cleaning data...\")\n",
        "\n",
        "    # Load MAIN file\n",
        "    print(f\"  Loading {Config.MAIN_FILE}...\")\n",
        "    main_df = pd.read_excel(Config.MAIN_FILE)\n",
        "    initial_main_count = len(main_df)\n",
        "\n",
        "    # Filter out missing Bias labels from MAIN\n",
        "    main_df = main_df[main_df['Bias'].notna() & (main_df['Bias'] != '')]\n",
        "    filtered_main_count = len(main_df)\n",
        "    print(f\"    MAIN: {initial_main_count} rows → {filtered_main_count} rows (removed {initial_main_count - filtered_main_count} with missing labels)\")\n",
        "\n",
        "    # Load and concatenate IAA files\n",
        "    iaa_dfs = []\n",
        "    for iaa_file in Config.IAA_FILES:\n",
        "        if os.path.exists(iaa_file):\n",
        "            print(f\"  Loading {iaa_file}...\")\n",
        "            iaa_df_temp = pd.read_excel(iaa_file)\n",
        "            initial_count = len(iaa_df_temp)\n",
        "\n",
        "            # Check both 'Bias' and 'Bais' (typo in IAA files)\n",
        "            if 'Bais' in iaa_df_temp.columns:\n",
        "                iaa_df_temp['Bias'] = iaa_df_temp['Bais']\n",
        "\n",
        "            iaa_df_temp = iaa_df_temp[iaa_df_temp['Bias'].notna() & (iaa_df_temp['Bias'] != '')]\n",
        "            filtered_count = len(iaa_df_temp)\n",
        "\n",
        "            if filtered_count > 0:\n",
        "                iaa_dfs.append(iaa_df_temp)\n",
        "                print(f\"    {iaa_file}: {initial_count} rows → {filtered_count} rows\")\n",
        "            else:\n",
        "                print(f\"    {iaa_file}: No valid labels found, skipping.\")\n",
        "        else:\n",
        "            print(f\"  Warning: {iaa_file} not found, skipping.\")\n",
        "\n",
        "    # Concatenate all IAA data\n",
        "    if iaa_dfs:\n",
        "        iaa_df = pd.concat(iaa_dfs, ignore_index=True)\n",
        "        print(f\"\\n  Total IAA data: {len(iaa_df)} rows with valid labels\")\n",
        "    else:\n",
        "        print(\"\\n  Warning: No valid IAA data found!\")\n",
        "        iaa_df = pd.DataFrame()\n",
        "\n",
        "    return main_df, iaa_df\n",
        "\n",
        "\n",
        "def map_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Map raw bias labels to standardized 4-class labels.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['Bias_Mapped'] = df['Bias'].map(Config.LABEL_MAP)\n",
        "\n",
        "    # Handle any unmapped labels\n",
        "    unmapped = df[df['Bias_Mapped'].isna()]['Bias'].unique()\n",
        "    if len(unmapped) > 0:\n",
        "        print(f\"  Warning: Unmapped labels found: {unmapped}\")\n",
        "        print(f\"  Mapping these to 'Others'\")\n",
        "        df['Bias_Mapped'] = df['Bias_Mapped'].fillna('Others')\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_majority_vote(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Apply majority voting to IAA data grouped by Text/ID.\"\"\"\n",
        "    print(\"\\n  Applying majority vote to collapse duplicate annotations...\")\n",
        "\n",
        "    # Create a unique text identifier\n",
        "    df['Text_ID'] = df['ID'].astype(str) + \"_\" + df['Text'].str[:50]\n",
        "\n",
        "    gold_standard_rows = []\n",
        "\n",
        "    for text_id, group in df.groupby('Text_ID'):\n",
        "        # Get most common label (mode)\n",
        "        labels = group['Bias_Mapped'].tolist()\n",
        "        label_counts = Counter(labels)\n",
        "        majority_label = label_counts.most_common(1)[0][0]\n",
        "\n",
        "        # Take first row and update its label\n",
        "        gold_row = group.iloc[0].copy()\n",
        "        gold_row['Bias_Mapped'] = majority_label\n",
        "        gold_row['Annotator_Count'] = len(group)\n",
        "        gold_standard_rows.append(gold_row)\n",
        "\n",
        "    result_df = pd.DataFrame(gold_standard_rows)\n",
        "    print(f\"    Collapsed {len(df)} annotations → {len(result_df)} unique texts\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "def create_train_test_split(main_df: pd.DataFrame, iaa_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Create training and test sets following the silver/gold strategy.\"\"\"\n",
        "    print(\"\\n[STEP 2] Creating train/test splits...\")\n",
        "\n",
        "    # --- UPDATED LOGIC START ---\n",
        "    # Get unique text IDs from IAA (use ID if Text_ID doesn't exist yet)\n",
        "    unique_ids = iaa_df['Text_ID'].unique() if 'Text_ID' in iaa_df.columns else iaa_df['ID'].unique()\n",
        "    print(f\"  Total unique IAA texts: {len(unique_ids)}\")\n",
        "\n",
        "    # Split by IDs (80/20)\n",
        "    train_ids, test_ids = train_test_split(\n",
        "        unique_ids,\n",
        "        test_size=(1 - Config.IAA_TRAIN_SPLIT),\n",
        "        random_state=Config.RANDOM_STATE,\n",
        "        stratify=None\n",
        "    )\n",
        "\n",
        "    print(f\"  IAA split: {len(train_ids)} train IDs, {len(test_ids)} test IDs\")\n",
        "\n",
        "    # Split IAA data (Using fallback logic for filtering)\n",
        "    if 'Text_ID' in iaa_df.columns:\n",
        "        iaa_train = iaa_df[iaa_df['Text_ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['Text_ID'].isin(test_ids)].copy()\n",
        "    else:\n",
        "        iaa_train = iaa_df[iaa_df['ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['ID'].isin(test_ids)].copy()\n",
        "    # --- UPDATED LOGIC END ---\n",
        "\n",
        "    # Apply majority vote to both\n",
        "    iaa_train_collapsed = apply_majority_vote(iaa_train)\n",
        "    iaa_test_collapsed = apply_majority_vote(iaa_test)\n",
        "\n",
        "    # Combine MAIN + IAA_train for training set\n",
        "    train_df = pd.concat([main_df, iaa_train_collapsed], ignore_index=True)\n",
        "    test_df = iaa_test_collapsed\n",
        "\n",
        "    print(f\"\\n  Final training set: {len(train_df)} samples\")\n",
        "    print(f\"    - From MAIN (silver): {len(main_df)}\")\n",
        "    print(f\"    - From IAA (gold): {len(iaa_train_collapsed)}\")\n",
        "    print(f\"  Final test set: {len(test_df)} samples (gold standard)\")\n",
        "\n",
        "    # Print class distribution\n",
        "    print(\"\\n  Training set class distribution:\")\n",
        "    print(train_df['Bias_Mapped'].value_counts())\n",
        "    print(\"\\n  Test set class distribution:\")\n",
        "    print(test_df['Bias_Mapped'].value_counts())\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# XLM-ROBERTA MODEL\n",
        "# ============================================================================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for training.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro')\n",
        "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted\n",
        "    }\n",
        "\n",
        "\n",
        "def prepare_dataset(df: pd.DataFrame, tokenizer, text_column: str = 'Text'):\n",
        "    \"\"\"Prepare dataset for transformer training.\"\"\"\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "    # Prepare data\n",
        "    data_dict = {\n",
        "        'text': df[text_column].tolist(),\n",
        "        'label': df['Bias_Mapped'].map(Config.LABEL2ID).tolist()\n",
        "    }\n",
        "\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n",
        "class XLMRoBERTaBiasDetector:\n",
        "    \"\"\"XLM-RoBERTa model for bias detection.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        print(f\"\\n[MODEL] Initializing XLM-RoBERTa Bias Detector\")\n",
        "        print(f\"  Model: {Config.MODEL_NAME}\")\n",
        "\n",
        "    def train(self, train_df: pd.DataFrame, eval_df: pd.DataFrame = None):\n",
        "        \"\"\"Train the model.\"\"\"\n",
        "        print(\"\\n[STEP 3] Training XLM-RoBERTa...\")\n",
        "\n",
        "        # Load tokenizer and model\n",
        "        print(f\"  Loading tokenizer and model: {Config.MODEL_NAME}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            Config.MODEL_NAME,\n",
        "            num_labels=len(Config.TARGET_LABELS),\n",
        "            id2label=Config.ID2LABEL,\n",
        "            label2id=Config.LABEL2ID\n",
        "        )\n",
        "\n",
        "        # Prepare datasets\n",
        "        print(\"  Preparing datasets...\")\n",
        "        train_dataset = prepare_dataset(train_df, self.tokenizer)\n",
        "        eval_dataset = None\n",
        "        if eval_df is not None and len(eval_df) > 0:\n",
        "            eval_dataset = prepare_dataset(eval_df, self.tokenizer)\n",
        "\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            **Config.TRAINING_ARGS,\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        # Trainer\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] if eval_dataset else None\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        print(\"\\n  Starting training...\")\n",
        "        print(f\"    Epochs: {Config.TRAINING_ARGS['num_train_epochs']}\")\n",
        "        print(f\"    Batch size: {Config.TRAINING_ARGS['per_device_train_batch_size']}\")\n",
        "        print(f\"    Learning rate: {Config.TRAINING_ARGS['learning_rate']}\")\n",
        "\n",
        "        self.trainer.train()\n",
        "\n",
        "        print(\"\\n  ✓ Training completed successfully!\")\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[str]:\n",
        "        \"\"\"Predict labels for texts.\"\"\"\n",
        "        if not texts:\n",
        "            return []\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return [Config.ID2LABEL[pred.item()] for pred in predictions]\n",
        "\n",
        "    def predict_proba(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Predict probabilities for each class.\"\"\"\n",
        "        if not texts:\n",
        "            return np.array([])\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return probs.numpy()\n",
        "\n",
        "    def evaluate(self, test_df: pd.DataFrame):\n",
        "        \"\"\"Evaluate model on test set with detailed metrics.\"\"\"\n",
        "        print(\"\\n[STEP 4] Evaluating XLM-RoBERTa...\")\n",
        "\n",
        "        texts = test_df['Text'].tolist()\n",
        "        true_labels = test_df['Bias_Mapped'].tolist()\n",
        "\n",
        "        # Get predictions\n",
        "        print(\"  Generating predictions...\")\n",
        "        predictions = self.predict(texts)\n",
        "\n",
        "        # Overall metrics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLASSIFICATION REPORT\")\n",
        "        print(\"=\"*80)\n",
        "        print(classification_report(\n",
        "            true_labels,\n",
        "            predictions,\n",
        "            target_names=Config.TARGET_LABELS,\n",
        "            digits=4\n",
        "        ))\n",
        "\n",
        "        acc = accuracy_score(true_labels, predictions)\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro')\n",
        "        f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"OVERALL METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"  Accuracy:        {acc:.4f}\")\n",
        "        print(f\"  Macro F1-Score:  {f1_macro:.4f}\")\n",
        "        print(f\"  Weighted F1:     {f1_weighted:.4f}\")\n",
        "\n",
        "        # Language-specific analysis\n",
        "        if 'Source Language' in test_df.columns:\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"LANGUAGE-SPECIFIC PERFORMANCE\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for lang in ['Arabic', 'English']:\n",
        "                mask = test_df['Source Language'].str.contains(lang, case=False, na=False)\n",
        "                if mask.sum() > 0:\n",
        "                    lang_true = [true_labels[i] for i in range(len(true_labels)) if mask.iloc[i]]\n",
        "                    lang_pred = [predictions[i] for i in range(len(predictions)) if mask.iloc[i]]\n",
        "\n",
        "                    lang_acc = accuracy_score(lang_true, lang_pred)\n",
        "                    lang_f1 = f1_score(lang_true, lang_pred, average='macro')\n",
        "\n",
        "                    print(f\"\\n  {lang}:\")\n",
        "                    print(f\"    Samples: {len(lang_true)}\")\n",
        "                    print(f\"    Accuracy: {lang_acc:.4f}\")\n",
        "                    print(f\"    Macro F1: {lang_f1:.4f}\")\n",
        "\n",
        "        # Confusion matrix\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CONFUSION MATRIX\")\n",
        "        print(\"=\"*80)\n",
        "        cm = confusion_matrix(true_labels, predictions, labels=Config.TARGET_LABELS)\n",
        "        print(\"\\nTrue (rows) vs Predicted (columns):\")\n",
        "        cm_df = pd.DataFrame(cm, index=Config.TARGET_LABELS, columns=Config.TARGET_LABELS)\n",
        "        print(cm_df)\n",
        "\n",
        "        return {\n",
        "            'predictions': predictions,\n",
        "            'accuracy': acc,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "\n",
        "    # Set random seeds\n",
        "    np.random.seed(Config.RANDOM_STATE)\n",
        "    torch.manual_seed(Config.RANDOM_STATE)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(Config.RANDOM_STATE)\n",
        "\n",
        "    # Load and prepare data\n",
        "    main_df, iaa_df = load_and_clean_data()\n",
        "\n",
        "    # Map labels\n",
        "    print(\"\\n[PREPROCESSING] Mapping labels...\")\n",
        "    main_df = map_labels(main_df)\n",
        "    if len(iaa_df) > 0:\n",
        "        iaa_df = map_labels(iaa_df)\n",
        "\n",
        "    # Create splits\n",
        "    train_df, test_df = create_train_test_split(main_df, iaa_df)\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = XLMRoBERTaBiasDetector()\n",
        "    model.train(train_df, test_df)\n",
        "\n",
        "    # Evaluate\n",
        "    if len(test_df) > 0:\n",
        "        results = model.evaluate(test_df)\n",
        "    else:\n",
        "        print(\"\\n  Warning: No test data available for evaluation\")\n",
        "        results = None\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TESTING COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return model, results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# INFERENCE EXAMPLES\n",
        "# ============================================================================\n",
        "\n",
        "def test_predictions(model: XLMRoBERTaBiasDetector):\n",
        "    \"\"\"Test the model with example texts.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXAMPLE PREDICTIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    sample_texts = [\n",
        "        # English examples\n",
        "        \"Hamas terrorists launched brutal attacks on innocent Israeli civilians.\",\n",
        "        \"Israeli forces killed dozens of Palestinian civilians in Gaza today.\",\n",
        "        \"The conflict continues with casualties on both sides.\",\n",
        "\n",
        "        # Arabic examples\n",
        "        \"الاحتلال الإسرائيلي يقصف المدنيين في غزة\",\n",
        "        \"حماس تطلق صواريخ على المدن الإسرائيلية\",\n",
        "        \"استمرار الصراع مع سقوط ضحايا من الجانبين\"\n",
        "    ]\n",
        "\n",
        "    predictions = model.predict(sample_texts)\n",
        "    probabilities = model.predict_proba(sample_texts)\n",
        "\n",
        "    for i, (text, pred, probs) in enumerate(zip(sample_texts, predictions, probabilities), 1):\n",
        "        print(f\"\\n[Example {i}]\")\n",
        "        print(f\"  Text: {text}\")\n",
        "        print(f\"  Prediction: {pred}\")\n",
        "        print(f\"  Confidence:\")\n",
        "        for label, prob in zip(Config.TARGET_LABELS, probs):\n",
        "            print(f\"    {label}: {prob:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run main pipeline\n",
        "    model, results = main()\n",
        "\n",
        "    # Test with examples\n",
        "    if model is not None:\n",
        "        test_predictions(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 1. SETUP PATHS\n",
        "# Based on your logs, this is your best checkpoint\n",
        "checkpoint_path = \"./results_xlm_roberta/checkpoint-2940\"\n",
        "original_model_name = \"xlm-roberta-base\"\n",
        "final_output_dir = \"./final_xlm_roberta_complete\"\n",
        "\n",
        "print(f\"🔧 Fixing model loading...\")\n",
        "\n",
        "# 2. LOAD MODEL (From your fine-tuned checkpoint)\n",
        "print(f\"   Loading WEIGHTS from: {checkpoint_path}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "\n",
        "# 3. LOAD TOKENIZER (From the original base, since it's missing in the checkpoint)\n",
        "print(f\"   Loading TOKENIZER from: {original_model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(original_model_name)\n",
        "\n",
        "# 4. SAVE EVERYTHING TOGETHER (This creates the valid folder)\n",
        "print(f\"   Saving complete model to: {final_output_dir}\")\n",
        "model.save_pretrained(final_output_dir)\n",
        "tokenizer.save_pretrained(final_output_dir)\n",
        "\n",
        "# 5. VERIFY & ZIP\n",
        "if os.path.exists(os.path.join(final_output_dir, \"sentencepiece.bpe.model\")):\n",
        "    print(\"   ✅ Tokenizer file successfully restored!\")\n",
        "\n",
        "print(\"📦 Zipping for download...\")\n",
        "shutil.make_archive(\"xlm_roberta_bias_model\", 'zip', final_output_dir)\n",
        "\n",
        "print(\"\\n✅ DONE! Download 'xlm_roberta_bias_model.zip' from the files tab.\")\n",
        "\n",
        "# Optional: Test Prediction to ensure it works\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "inputs = tokenizer(\"Testing the fixed model\", return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "print(\"\\nTest Run Successful. Model Output Shape:\", outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKOkdyctKInB",
        "outputId": "d778004b-fae2-4cc6-eb5a-8efa57bdf8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Fixing model loading...\n",
            "   Loading WEIGHTS from: ./results_xlm_roberta/checkpoint-2940\n",
            "   Loading TOKENIZER from: xlm-roberta-base\n",
            "   Saving complete model to: ./final_xlm_roberta_complete\n",
            "   ✅ Tokenizer file successfully restored!\n",
            "📦 Zipping for download...\n",
            "\n",
            "✅ DONE! Download 'xlm_roberta_bias_model.zip' from the files tab.\n",
            "\n",
            "Test Run Successful. Model Output Shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP: UNZIP THE MODEL\n",
        "# ==========================================\n",
        "zip_path = \"/content/xlm_roberta_bias_model.zip\"\n",
        "extract_path = \"./my_production_model\"\n",
        "\n",
        "# Clean up previous extraction if exists\n",
        "if os.path.exists(extract_path):\n",
        "    shutil.rmtree(extract_path)\n",
        "\n",
        "print(f\"📦 Unzipping {zip_path}...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"✅ Model extracted to: {extract_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOAD MODEL & TOKENIZER\n",
        "# ==========================================\n",
        "print(\"   Loading model into memory...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load from the extracted folder\n",
        "tokenizer = AutoTokenizer.from_pretrained(extract_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(extract_path)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Helper to get human-readable labels (Reverse the mapping from your config)\n",
        "# Update this if your labels are different, but this matches your previous config\n",
        "id2label = {\n",
        "    0: 'Unbiased',\n",
        "    1: 'Biased Against Palestine',\n",
        "    2: 'Biased Against Israel',\n",
        "    3: 'Others'\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 3. PREDICTION FUNCTION\n",
        "# ==========================================\n",
        "def predict_bias(texts):\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Move to GPU\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.softmax(outputs.logits, dim=-1)\n",
        "        predictions = torch.argmax(probs, dim=-1)\n",
        "\n",
        "    # Format results\n",
        "    results = []\n",
        "    for i, pred_id in enumerate(predictions):\n",
        "        pred_label = id2label.get(pred_id.item(), \"Unknown\")\n",
        "        confidence = probs[i][pred_id].item()\n",
        "        results.append((pred_label, confidence))\n",
        "\n",
        "    return results\n",
        "\n",
        "# ==========================================\n",
        "# 4. RUN TEST EXAMPLES\n",
        "# ==========================================\n",
        "test_sentences = [\n",
        "    # English Examples\n",
        "    \"The army neutralized the terrorist threat in the region.\",\n",
        "    \"Civilians are suffering due to the brutal blockade.\",\n",
        "    \"Peace talks are scheduled to resume next week in Cairo.\",\n",
        "\n",
        "    # Arabic Examples\n",
        "    \"قامت القوات باستهداف المدنيين العزل في قطاع غزة.\",  # Biased/Charged language\n",
        "    \"أعلنت وزارة الصحة عن ارتفاع عدد الضحايا.\",         # Neutral reporting\n",
        "    \"إسرائيل تدافع عن نفسها ضد الهجمات الصاروخية.\"      # Biased perspective\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🔎 MODEL INFERENCE TEST\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "predictions = predict_bias(test_sentences)\n",
        "\n",
        "for text, (label, conf) in zip(test_sentences, predictions):\n",
        "    print(f\"\\n📝 Text: {text}\")\n",
        "    print(f\"🏷️ Label: {label}\")\n",
        "    print(f\"📊 Confidence: {conf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnvwYecVM_fx",
        "outputId": "c106a840-c371-4b6f-fc93-22dc72039027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Unzipping /content/xlm_roberta_bias_model.zip...\n",
            "✅ Model extracted to: ./my_production_model\n",
            "   Loading model into memory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer you are loading from './my_production_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "🔎 MODEL INFERENCE TEST\n",
            "==================================================\n",
            "\n",
            "📝 Text: The army neutralized the terrorist threat in the region.\n",
            "🏷️ Label: Biased Against Palestine\n",
            "📊 Confidence: 0.7837\n",
            "\n",
            "📝 Text: Civilians are suffering due to the brutal blockade.\n",
            "🏷️ Label: Unbiased\n",
            "📊 Confidence: 0.6811\n",
            "\n",
            "📝 Text: Peace talks are scheduled to resume next week in Cairo.\n",
            "🏷️ Label: Unbiased\n",
            "📊 Confidence: 0.8699\n",
            "\n",
            "📝 Text: قامت القوات باستهداف المدنيين العزل في قطاع غزة.\n",
            "🏷️ Label: Unbiased\n",
            "📊 Confidence: 0.6133\n",
            "\n",
            "📝 Text: أعلنت وزارة الصحة عن ارتفاع عدد الضحايا.\n",
            "🏷️ Label: Unbiased\n",
            "📊 Confidence: 0.8293\n",
            "\n",
            "📝 Text: إسرائيل تدافع عن نفسها ضد الهجمات الصاروخية.\n",
            "🏷️ Label: Unbiased\n",
            "📊 Confidence: 0.8706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "XLM-RoBERTa Standalone Testing for FIGNEWS-2024 (FIXED VERSION)\n",
        "================================================================\n",
        "Fixes applied:\n",
        "1. Complete label mapping (including 'Biased against both Palestine and Israel' and 'Not Applicable')\n",
        "2. Class weight balancing using CustomTrainer with weighted CrossEntropyLoss\n",
        "3. Device management fix for GPU inference\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Core ML libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"XLM-ROBERTA STANDALONE TESTING (FIXED VERSION)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration for XLM-RoBERTa testing\"\"\"\n",
        "\n",
        "    # File paths\n",
        "    MAIN_FILE = \"/content/Main.xlsx\"\n",
        "    IAA_FILES = [\"/content/IAA-1.xlsx\", \"/content/IAA-2.xlsx\", \"/content/IAA-3.xlsx\", \"/content/IAA-4.xlsx\"]\n",
        "\n",
        "    # Label mapping - FIXED: Added missing mappings\n",
        "    LABEL_MAP = {\n",
        "        'Unbiased': 'Unbiased',\n",
        "        'Biased against Palestine': 'Biased Against Palestine',\n",
        "        'Biased Against Palestine': 'Biased Against Palestine',\n",
        "        'Biased against Israel': 'Biased Against Israel',\n",
        "        'Biased Against Israel': 'Biased Against Israel',\n",
        "        'Unclear': 'Others',\n",
        "        'Biased against others': 'Others',\n",
        "        'Biased against both': 'Others',\n",
        "        'Biased against both Palestine and Israel': 'Others',  # FIXED\n",
        "        'Not Applicable': 'Others',                           # FIXED\n",
        "        'Others': 'Others'\n",
        "    }\n",
        "\n",
        "    TARGET_LABELS = ['Unbiased', 'Biased Against Palestine', 'Biased Against Israel', 'Others']\n",
        "    LABEL2ID = {label: idx for idx, label in enumerate(TARGET_LABELS)}\n",
        "    ID2LABEL = {idx: label for label, idx in LABEL2ID.items()}\n",
        "\n",
        "    # Model configuration\n",
        "    MODEL_NAME = \"xlm-roberta-base\"\n",
        "\n",
        "    # Training parameters\n",
        "    IAA_TRAIN_SPLIT = 0.8\n",
        "    RANDOM_STATE = 42\n",
        "\n",
        "    # Training arguments - ADJUSTED for better handling of imbalance\n",
        "    TRAINING_ARGS = {\n",
        "        \"output_dir\": \"./results_xlm_roberta_fixed\",\n",
        "        \"num_train_epochs\": 4,\n",
        "        \"per_device_train_batch_size\": 16,\n",
        "        \"per_device_eval_batch_size\": 16,\n",
        "        \"learning_rate\": 2e-5,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"eval_strategy\": \"epoch\",\n",
        "        \"save_strategy\": \"epoch\",\n",
        "        \"load_best_model_at_end\": True,\n",
        "        \"metric_for_best_model\": \"f1_macro\",  # Focus on macro F1 for imbalanced data\n",
        "        \"logging_steps\": 50,\n",
        "        \"warmup_steps\": 200,  # Increased warmup\n",
        "        \"save_total_limit\": 2,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING & PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def load_and_clean_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load MAIN and IAA files, filter out rows with missing Bias labels.\"\"\"\n",
        "    print(\"\\n[STEP 1] Loading and cleaning data...\")\n",
        "\n",
        "    # Load MAIN file\n",
        "    print(f\"  Loading {Config.MAIN_FILE}...\")\n",
        "    main_df = pd.read_excel(Config.MAIN_FILE)\n",
        "    initial_main_count = len(main_df)\n",
        "\n",
        "    # Filter out missing Bias labels from MAIN\n",
        "    main_df = main_df[main_df['Bias'].notna() & (main_df['Bias'] != '')]\n",
        "    filtered_main_count = len(main_df)\n",
        "    print(f\"    MAIN: {initial_main_count} rows → {filtered_main_count} rows (removed {initial_main_count - filtered_main_count} with missing labels)\")\n",
        "\n",
        "    # Load and concatenate IAA files\n",
        "    iaa_dfs = []\n",
        "    for iaa_file in Config.IAA_FILES:\n",
        "        if os.path.exists(iaa_file):\n",
        "            print(f\"  Loading {iaa_file}...\")\n",
        "            iaa_df_temp = pd.read_excel(iaa_file)\n",
        "            initial_count = len(iaa_df_temp)\n",
        "\n",
        "            # Check both 'Bias' and 'Bais' (typo in IAA files)\n",
        "            if 'Bais' in iaa_df_temp.columns:\n",
        "                iaa_df_temp['Bias'] = iaa_df_temp['Bais']\n",
        "\n",
        "            iaa_df_temp = iaa_df_temp[iaa_df_temp['Bias'].notna() & (iaa_df_temp['Bias'] != '')]\n",
        "            filtered_count = len(iaa_df_temp)\n",
        "\n",
        "            if filtered_count > 0:\n",
        "                iaa_dfs.append(iaa_df_temp)\n",
        "                print(f\"    {iaa_file}: {initial_count} rows → {filtered_count} rows\")\n",
        "            else:\n",
        "                print(f\"    {iaa_file}: No valid labels found, skipping.\")\n",
        "        else:\n",
        "            print(f\"  Warning: {iaa_file} not found, skipping.\")\n",
        "\n",
        "    # Concatenate all IAA data\n",
        "    if iaa_dfs:\n",
        "        iaa_df = pd.concat(iaa_dfs, ignore_index=True)\n",
        "        print(f\"\\n  Total IAA data: {len(iaa_df)} rows with valid labels\")\n",
        "    else:\n",
        "        print(\"\\n  Warning: No valid IAA data found!\")\n",
        "        iaa_df = pd.DataFrame()\n",
        "\n",
        "    return main_df, iaa_df\n",
        "\n",
        "\n",
        "def map_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Map raw bias labels to standardized 4-class labels.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['Bias_Mapped'] = df['Bias'].map(Config.LABEL_MAP)\n",
        "\n",
        "    # Handle any unmapped labels\n",
        "    unmapped = df[df['Bias_Mapped'].isna()]['Bias'].unique()\n",
        "    if len(unmapped) > 0:\n",
        "        print(f\"  ⚠️ WARNING: Unmapped labels found: {unmapped}\")\n",
        "        print(f\"  These will cause errors - please update Config.LABEL_MAP!\")\n",
        "        # Still fill with 'Others' as fallback\n",
        "        df['Bias_Mapped'] = df['Bias_Mapped'].fillna('Others')\n",
        "    else:\n",
        "        print(f\"  ✓ All labels mapped successfully\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_majority_vote(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Apply majority voting to IAA data grouped by Text/ID.\"\"\"\n",
        "    print(\"\\n  Applying majority vote to collapse duplicate annotations...\")\n",
        "\n",
        "    # Create a unique text identifier\n",
        "    df['Text_ID'] = df['ID'].astype(str) + \"_\" + df['Text'].str[:50]\n",
        "\n",
        "    gold_standard_rows = []\n",
        "\n",
        "    for text_id, group in df.groupby('Text_ID'):\n",
        "        # Get most common label (mode)\n",
        "        labels = group['Bias_Mapped'].tolist()\n",
        "        label_counts = Counter(labels)\n",
        "        majority_label = label_counts.most_common(1)[0][0]\n",
        "\n",
        "        # Take first row and update its label\n",
        "        gold_row = group.iloc[0].copy()\n",
        "        gold_row['Bias_Mapped'] = majority_label\n",
        "        gold_row['Annotator_Count'] = len(group)\n",
        "        gold_standard_rows.append(gold_row)\n",
        "\n",
        "    result_df = pd.DataFrame(gold_standard_rows)\n",
        "    print(f\"    Collapsed {len(df)} annotations → {len(result_df)} unique texts\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "def create_train_test_split(main_df: pd.DataFrame, iaa_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Create training and test sets following the silver/gold strategy.\"\"\"\n",
        "    print(\"\\n[STEP 2] Creating train/test splits...\")\n",
        "\n",
        "    # Get unique text IDs from IAA\n",
        "    unique_ids = iaa_df['Text_ID'].unique() if 'Text_ID' in iaa_df.columns else iaa_df['ID'].unique()\n",
        "    print(f\"  Total unique IAA texts: {len(unique_ids)}\")\n",
        "\n",
        "    # Split by IDs (80/20)\n",
        "    train_ids, test_ids = train_test_split(\n",
        "        unique_ids,\n",
        "        test_size=(1 - Config.IAA_TRAIN_SPLIT),\n",
        "        random_state=Config.RANDOM_STATE,\n",
        "        stratify=None\n",
        "    )\n",
        "\n",
        "    print(f\"  IAA split: {len(train_ids)} train IDs, {len(test_ids)} test IDs\")\n",
        "\n",
        "    # Split IAA data\n",
        "    if 'Text_ID' in iaa_df.columns:\n",
        "        iaa_train = iaa_df[iaa_df['Text_ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['Text_ID'].isin(test_ids)].copy()\n",
        "    else:\n",
        "        iaa_train = iaa_df[iaa_df['ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['ID'].isin(test_ids)].copy()\n",
        "\n",
        "    # Apply majority vote to both\n",
        "    iaa_train_collapsed = apply_majority_vote(iaa_train)\n",
        "    iaa_test_collapsed = apply_majority_vote(iaa_test)\n",
        "\n",
        "    # Combine MAIN + IAA_train for training set\n",
        "    train_df = pd.concat([main_df, iaa_train_collapsed], ignore_index=True)\n",
        "    test_df = iaa_test_collapsed\n",
        "\n",
        "    print(f\"\\n  Final training set: {len(train_df)} samples\")\n",
        "    print(f\"    - From MAIN (silver): {len(main_df)}\")\n",
        "    print(f\"    - From IAA (gold): {len(iaa_train_collapsed)}\")\n",
        "    print(f\"  Final test set: {len(test_df)} samples (gold standard)\")\n",
        "\n",
        "    # Print class distribution\n",
        "    print(\"\\n  Training set class distribution:\")\n",
        "    train_dist = train_df['Bias_Mapped'].value_counts()\n",
        "    print(train_dist)\n",
        "    print(\"\\n  Class proportions:\")\n",
        "    print((train_dist / len(train_df) * 100).round(2))\n",
        "\n",
        "    print(\"\\n  Test set class distribution:\")\n",
        "    print(test_df['Bias_Mapped'].value_counts())\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CUSTOM TRAINER WITH CLASS WEIGHTS\n",
        "# ============================================================================\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Custom Trainer that applies class weights to loss function.\"\"\"\n",
        "\n",
        "    def __init__(self, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        \"\"\"Override compute_loss to use weighted CrossEntropyLoss.\"\"\"\n",
        "        labels = inputs.pop(\"labels\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Compute weighted loss\n",
        "        if self.class_weights is not None:\n",
        "            # Move weights to same device as logits\n",
        "            weights = self.class_weights.to(logits.device)\n",
        "            loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
        "        else:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# XLM-ROBERTA MODEL\n",
        "# ============================================================================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for training.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro')\n",
        "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted\n",
        "    }\n",
        "\n",
        "\n",
        "def prepare_dataset(df: pd.DataFrame, tokenizer, text_column: str = 'Text'):\n",
        "    \"\"\"Prepare dataset for transformer training.\"\"\"\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "    # Prepare data\n",
        "    data_dict = {\n",
        "        'text': df[text_column].tolist(),\n",
        "        'label': df['Bias_Mapped'].map(Config.LABEL2ID).tolist()\n",
        "    }\n",
        "\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n",
        "class XLMRoBERTaBiasDetector:\n",
        "    \"\"\"XLM-RoBERTa model for bias detection with class weight balancing.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"\\n[MODEL] Initializing XLM-RoBERTa Bias Detector\")\n",
        "        print(f\"  Model: {Config.MODEL_NAME}\")\n",
        "        print(f\"  Device: {self.device}\")\n",
        "\n",
        "    def train(self, train_df: pd.DataFrame, eval_df: pd.DataFrame = None):\n",
        "        \"\"\"Train the model with class weight balancing.\"\"\"\n",
        "        print(\"\\n[STEP 3] Training XLM-RoBERTa with Class Weight Balancing...\")\n",
        "\n",
        "        # Load tokenizer and model\n",
        "        print(f\"  Loading tokenizer and model: {Config.MODEL_NAME}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            Config.MODEL_NAME,\n",
        "            num_labels=len(Config.TARGET_LABELS),\n",
        "            id2label=Config.ID2LABEL,\n",
        "            label2id=Config.LABEL2ID\n",
        "        )\n",
        "\n",
        "        # Move model to device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Calculate class weights\n",
        "        print(\"\\n  Calculating class weights to handle imbalance...\")\n",
        "        labels = train_df['Bias_Mapped'].map(Config.LABEL2ID).values\n",
        "        unique_labels = np.unique(labels)\n",
        "\n",
        "        class_weights = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_labels,\n",
        "            y=labels\n",
        "        )\n",
        "\n",
        "        # Convert to tensor\n",
        "        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "        print(\"  Class weights:\")\n",
        "        for label_id, weight in zip(unique_labels, class_weights):\n",
        "            label_name = Config.ID2LABEL[label_id]\n",
        "            print(f\"    {label_name}: {weight:.4f}\")\n",
        "\n",
        "        # Prepare datasets\n",
        "        print(\"\\n  Preparing datasets...\")\n",
        "        train_dataset = prepare_dataset(train_df, self.tokenizer)\n",
        "        eval_dataset = None\n",
        "        if eval_df is not None and len(eval_df) > 0:\n",
        "            eval_dataset = prepare_dataset(eval_df, self.tokenizer)\n",
        "\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            **Config.TRAINING_ARGS,\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        # Use custom weighted trainer\n",
        "        self.trainer = WeightedTrainer(\n",
        "            class_weights=class_weights_tensor,\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] if eval_dataset else None\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        print(\"\\n  Starting training...\")\n",
        "        print(f\"    Epochs: {Config.TRAINING_ARGS['num_train_epochs']}\")\n",
        "        print(f\"    Batch size: {Config.TRAINING_ARGS['per_device_train_batch_size']}\")\n",
        "        print(f\"    Learning rate: {Config.TRAINING_ARGS['learning_rate']}\")\n",
        "        print(f\"    Using class weights: Yes ✓\")\n",
        "\n",
        "        self.trainer.train()\n",
        "\n",
        "        print(\"\\n  ✓ Training completed successfully!\")\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[str]:\n",
        "        \"\"\"Predict labels for texts - FIXED: proper device management.\"\"\"\n",
        "        if not texts:\n",
        "            return []\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # FIXED: Move inputs to the same device as model\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return [Config.ID2LABEL[pred.item()] for pred in predictions]\n",
        "\n",
        "    def predict_proba(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Predict probabilities for each class - FIXED: proper device management.\"\"\"\n",
        "        if not texts:\n",
        "            return np.array([])\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # FIXED: Move inputs to the same device as model\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return probs.cpu().numpy()\n",
        "\n",
        "    def evaluate(self, test_df: pd.DataFrame):\n",
        "        \"\"\"Evaluate model on test set with detailed metrics.\"\"\"\n",
        "        print(\"\\n[STEP 4] Evaluating XLM-RoBERTa...\")\n",
        "\n",
        "        texts = test_df['Text'].tolist()\n",
        "        true_labels = test_df['Bias_Mapped'].tolist()\n",
        "\n",
        "        # Get predictions\n",
        "        print(\"  Generating predictions...\")\n",
        "        predictions = self.predict(texts)\n",
        "\n",
        "        # Overall metrics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLASSIFICATION REPORT\")\n",
        "        print(\"=\"*80)\n",
        "        print(classification_report(\n",
        "            true_labels,\n",
        "            predictions,\n",
        "            target_names=Config.TARGET_LABELS,\n",
        "            digits=4\n",
        "        ))\n",
        "\n",
        "        acc = accuracy_score(true_labels, predictions)\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro')\n",
        "        f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"OVERALL METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"  Accuracy:        {acc:.4f}\")\n",
        "        print(f\"  Macro F1-Score:  {f1_macro:.4f}\")\n",
        "        print(f\"  Weighted F1:     {f1_weighted:.4f}\")\n",
        "\n",
        "        # Language-specific analysis\n",
        "        if 'Source Language' in test_df.columns:\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(\"LANGUAGE-SPECIFIC PERFORMANCE\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            for lang in ['Arabic', 'English']:\n",
        "                mask = test_df['Source Language'].str.contains(lang, case=False, na=False)\n",
        "                if mask.sum() > 0:\n",
        "                    lang_true = [true_labels[i] for i in range(len(true_labels)) if mask.iloc[i]]\n",
        "                    lang_pred = [predictions[i] for i in range(len(predictions)) if mask.iloc[i]]\n",
        "\n",
        "                    lang_acc = accuracy_score(lang_true, lang_pred)\n",
        "                    lang_f1 = f1_score(lang_true, lang_pred, average='macro')\n",
        "\n",
        "                    print(f\"\\n  {lang}:\")\n",
        "                    print(f\"    Samples: {len(lang_true)}\")\n",
        "                    print(f\"    Accuracy: {lang_acc:.4f}\")\n",
        "                    print(f\"    Macro F1: {lang_f1:.4f}\")\n",
        "\n",
        "        # Confusion matrix\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CONFUSION MATRIX\")\n",
        "        print(\"=\"*80)\n",
        "        cm = confusion_matrix(true_labels, predictions, labels=Config.TARGET_LABELS)\n",
        "        print(\"\\nTrue (rows) vs Predicted (columns):\")\n",
        "        cm_df = pd.DataFrame(cm, index=Config.TARGET_LABELS, columns=Config.TARGET_LABELS)\n",
        "        print(cm_df)\n",
        "\n",
        "        return {\n",
        "            'predictions': predictions,\n",
        "            'accuracy': acc,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "\n",
        "    # Set random seeds\n",
        "    np.random.seed(Config.RANDOM_STATE)\n",
        "    torch.manual_seed(Config.RANDOM_STATE)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(Config.RANDOM_STATE)\n",
        "\n",
        "    # Load and prepare data\n",
        "    main_df, iaa_df = load_and_clean_data()\n",
        "\n",
        "    # Map labels\n",
        "    print(\"\\n[PREPROCESSING] Mapping labels...\")\n",
        "    main_df = map_labels(main_df)\n",
        "    if len(iaa_df) > 0:\n",
        "        iaa_df = map_labels(iaa_df)\n",
        "\n",
        "    # Create splits\n",
        "    train_df, test_df = create_train_test_split(main_df, iaa_df)\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = XLMRoBERTaBiasDetector()\n",
        "    model.train(train_df, test_df)\n",
        "\n",
        "    # Evaluate\n",
        "    if len(test_df) > 0:\n",
        "        results = model.evaluate(test_df)\n",
        "    else:\n",
        "        print(\"\\n  Warning: No test data available for evaluation\")\n",
        "        results = None\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TESTING COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return model, results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# INFERENCE EXAMPLES\n",
        "# ============================================================================\n",
        "\n",
        "def test_predictions(model: XLMRoBERTaBiasDetector):\n",
        "    \"\"\"Test the model with example texts.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXAMPLE PREDICTIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    sample_texts = [\n",
        "        # English examples\n",
        "        \"Hamas terrorists launched brutal attacks on innocent Israeli civilians.\",\n",
        "        \"Israeli forces killed dozens of Palestinian civilians in Gaza today.\",\n",
        "        \"The conflict continues with casualties on both sides.\",\n",
        "        \"Civilians are suffering due to the brutal blockade.\",\n",
        "\n",
        "        # Arabic examples\n",
        "        \"الاحتلال الإسرائيلي يقصف المدنيين في غزة\",\n",
        "        \"حماس تطلق صواريخ على المدن الإسرائيلية\",\n",
        "        \"استمرار الصراع مع سقوط ضحايا من الجانبين\",\n",
        "        \"قامت القوات باستهداف المدنيين العزل في قطاع غزة\"\n",
        "    ]\n",
        "\n",
        "    predictions = model.predict(sample_texts)\n",
        "    probabilities = model.predict_proba(sample_texts)\n",
        "\n",
        "    for i, (text, pred, probs) in enumerate(zip(sample_texts, predictions, probabilities), 1):\n",
        "        print(f\"\\n[Example {i}]\")\n",
        "        print(f\"  Text: {text}\")\n",
        "        print(f\"  Prediction: {pred}\")\n",
        "        print(f\"  Confidence:\")\n",
        "        for label, prob in zip(Config.TARGET_LABELS, probs):\n",
        "            print(f\"    {label}: {prob:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run main pipeline\n",
        "    model, results = main()\n",
        "\n",
        "    # Test with examples\n",
        "    if model is not None:\n",
        "        test_predictions(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6201d5b89ade4620840d10c81ec9d159",
            "00821ec2761d42feaf1253570fefd03c",
            "372dc74c92ca4962bb2730a39fac5a1d",
            "8cbf4d816e6b47bdb12501bdb3fc61d9",
            "a466652db2714a6891cea185e9f2db24",
            "5bd489ec5c854fb883b3acf1bc9d9622",
            "4d280e3637dc4532805984db18f22563",
            "918e8155e19c4826bb9a2e84356bf493",
            "dcab08aa58834a5b8a737cd8221db9da",
            "c5905281e060455fa0ee5546b85c91c8",
            "9fadbec210c94985b1d3049ee2262b36",
            "68a762f1bf0b48d6bd6e530be0032969",
            "cc924f1bbd5e4ad4b089f64be4234317",
            "664a073208ae45de8460e2ab42115472",
            "3a7ba8bb62114b85b4b822678b39e33e",
            "0fd5452486a74ab59f7c6c7fabe7b571",
            "d6a4a51db52c471a96913c4fa9904e47",
            "325d42af097d4081ab3707347274774f",
            "6870f559335c43ce88d1685bb6132916",
            "09b87a5bccd64137850ad8f9eb911734",
            "3070839325474d019add996003987c9a",
            "79d75c196df746eb9df496bb5cbf87eb",
            "ea8f9dd234194647b44587a0db4e7e14",
            "551b391ed08541ea93106502880d8e87",
            "0f40ac37688947bea4b49aba6dce3d2a",
            "c399173fdd0a4c9493dc4a42ec1f3d0c",
            "ba1b650f9a2f47faae7ef2ccea56cb93",
            "4482917ad5e447c595b95eb84147009e",
            "f8ccddfaa6074278add0b0e09c219d1f",
            "5e67d83347954cf1b9fc0ea33727a53e",
            "78a858aef135465b8de945bd7cf3d1de",
            "c0e05e8a90e24e01a5f145a03314f856",
            "65c2dff6c3db48a6a10ad26b94922e5b",
            "b36aaeb2f44040c0bab31d757033d078",
            "29c6c4db5c6c454c8b4f79e5e2f3f50a",
            "c0ccb7e3cc2d4396bc93dfc1772eda2c",
            "db74f02c28c34b80bbf23eda30bea4e6",
            "74a63cb9756d4576908dc3484eccb2fc",
            "744744c1c7fb44d2b8eab48fcc96ef16",
            "0e9f06dc701145908b15b6a243c4d517",
            "08ac82ce0e89472cb7864957fff63515",
            "a4cfd0fcf1ad4b5abab3d6b5ec9365c0",
            "d6c17f95c38343c9ba9167b026a5b689",
            "8e3f6d05a9d54f82aa6ee5f21804d5a3",
            "53e4a3c7019449b29286b0aa86e65c2d",
            "2666f535203a478883d79c54336a5d11",
            "ada110df58744a37a370e621e40853cc",
            "ca9fce0249db4319962c351da9fe997f",
            "eccf30f7c29a42d8bd76c3682eb27ce4",
            "f21d687ee8384df0849523b8569057d8",
            "77962a19886943cb90856fcb8fd10158",
            "92d5622ca5144830b6705786d261ed5c",
            "cdddfd1ce051444783059609d55a256a",
            "565aa18712fc44629bf9ee0e3c7f01ef",
            "cc85671e596f40b0b296d1d5b6019435",
            "e05b0ffaa9274be8ac4f751798b167e5",
            "6a34c4471ba74ed19fcb1ec0f81584dc",
            "5e931e839d004e0c96a6c1d9387505b2",
            "a6bed40ce803401bb5337a76977a224f",
            "eb16c796687e431b9fdc4b2aa2fbd5d6",
            "07e2647f51374b8f9872328de7c50929",
            "4cbe4c7449db499ab190d45f0b7c37fc",
            "44ad5b6e61b04d50b4a1d00f507b7d66",
            "e3d2ac11c0cb42d28b6bbd8c98789784",
            "828c8fb98bdd4ae9a852c64d80ab2c3f",
            "d2d7695acd4c4ec688142c21fd5075a1",
            "d2b85ce638c74b7da05d1e74d996b139",
            "ed6bcfab5d05415fb497e900108e6523",
            "07026c75f2be45c19f435c04bf1fb7f6",
            "3392509065cd436cae6925d70de1b641",
            "d379b8d16ebe4f54b7c7de31b717176c",
            "f87e99f6f0c847debbe5e7d5d686be3a",
            "e50342ceb3664434a2ef2e5b479cbe04",
            "72930583813d4eba92aa6b502ba573c6",
            "3d4ef962ae67461fb8a1297de0b8b05f",
            "9946c300023c4a5aaa757dd83f8edca0",
            "1c12b4476be34fd28a43c6ded083e923"
          ]
        },
        "collapsed": true,
        "id": "mJEVhEHfapnT",
        "outputId": "4e3ffd8b-c28d-4c87-8770-9414fc29b989"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "XLM-ROBERTA STANDALONE TESTING (FIXED VERSION)\n",
            "================================================================================\n",
            "\n",
            "[STEP 1] Loading and cleaning data...\n",
            "  Loading /content/Main.xlsx...\n",
            "    MAIN: 13500 rows → 10800 rows (removed 2700 with missing labels)\n",
            "  Loading /content/IAA-1.xlsx...\n",
            "    /content/IAA-1.xlsx: 1200 rows → 1200 rows\n",
            "  Loading /content/IAA-2.xlsx...\n",
            "    /content/IAA-2.xlsx: 1200 rows → 1200 rows\n",
            "  Loading /content/IAA-3.xlsx...\n",
            "    /content/IAA-3.xlsx: No valid labels found, skipping.\n",
            "  Loading /content/IAA-4.xlsx...\n",
            "    /content/IAA-4.xlsx: No valid labels found, skipping.\n",
            "\n",
            "  Total IAA data: 2400 rows with valid labels\n",
            "\n",
            "[PREPROCESSING] Mapping labels...\n",
            "  ✓ All labels mapped successfully\n",
            "  ✓ All labels mapped successfully\n",
            "\n",
            "[STEP 2] Creating train/test splits...\n",
            "  Total unique IAA texts: 1115\n",
            "  IAA split: 892 train IDs, 223 test IDs\n",
            "\n",
            "  Applying majority vote to collapse duplicate annotations...\n",
            "    Collapsed 1920 annotations → 960 unique texts\n",
            "\n",
            "  Applying majority vote to collapse duplicate annotations...\n",
            "    Collapsed 480 annotations → 240 unique texts\n",
            "\n",
            "  Final training set: 11760 samples\n",
            "    - From MAIN (silver): 10800\n",
            "    - From IAA (gold): 960\n",
            "  Final test set: 240 samples (gold standard)\n",
            "\n",
            "  Training set class distribution:\n",
            "Bias_Mapped\n",
            "Unbiased                    7425\n",
            "Biased Against Palestine    3169\n",
            "Others                       871\n",
            "Biased Against Israel        295\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Class proportions:\n",
            "Bias_Mapped\n",
            "Unbiased                    63.14\n",
            "Biased Against Palestine    26.95\n",
            "Others                       7.41\n",
            "Biased Against Israel        2.51\n",
            "Name: count, dtype: float64\n",
            "\n",
            "  Test set class distribution:\n",
            "Bias_Mapped\n",
            "Unbiased                    157\n",
            "Biased Against Palestine     62\n",
            "Others                       15\n",
            "Biased Against Israel         6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[MODEL] Initializing XLM-RoBERTa Bias Detector\n",
            "  Model: xlm-roberta-base\n",
            "  Device: cuda\n",
            "\n",
            "[STEP 3] Training XLM-RoBERTa with Class Weight Balancing...\n",
            "  Loading tokenizer and model: xlm-roberta-base...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6201d5b89ade4620840d10c81ec9d159"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68a762f1bf0b48d6bd6e530be0032969"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea8f9dd234194647b44587a0db4e7e14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b36aaeb2f44040c0bab31d757033d078"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53e4a3c7019449b29286b0aa86e65c2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Calculating class weights to handle imbalance...\n",
            "  Class weights:\n",
            "    Unbiased: 0.3960\n",
            "    Biased Against Palestine: 0.9277\n",
            "    Biased Against Israel: 9.9661\n",
            "    Others: 3.3754\n",
            "\n",
            "  Preparing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e05b0ffaa9274be8ac4f751798b167e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2b85ce638c74b7da05d1e74d996b139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Starting training...\n",
            "    Epochs: 4\n",
            "    Batch size: 16\n",
            "    Learning rate: 2e-05\n",
            "    Using class weights: Yes ✓\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2940' max='2940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2940/2940 1:14:47, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.426000</td>\n",
              "      <td>1.376134</td>\n",
              "      <td>0.470833</td>\n",
              "      <td>0.243732</td>\n",
              "      <td>0.468926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.342200</td>\n",
              "      <td>1.177565</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.349721</td>\n",
              "      <td>0.628848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.338800</td>\n",
              "      <td>1.150135</td>\n",
              "      <td>0.654167</td>\n",
              "      <td>0.351105</td>\n",
              "      <td>0.639177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.240400</td>\n",
              "      <td>1.194473</td>\n",
              "      <td>0.637500</td>\n",
              "      <td>0.360646</td>\n",
              "      <td>0.629320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ✓ Training completed successfully!\n",
            "\n",
            "[STEP 4] Evaluating XLM-RoBERTa...\n",
            "  Generating predictions...\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                Unbiased     0.0000    0.0000    0.0000         6\n",
            "Biased Against Palestine     0.4643    0.6290    0.5342        62\n",
            "   Biased Against Israel     0.2500    0.1333    0.1739        15\n",
            "                  Others     0.7568    0.7134    0.7344       157\n",
            "\n",
            "                accuracy                         0.6375       240\n",
            "               macro avg     0.3678    0.3689    0.3606       240\n",
            "            weighted avg     0.6306    0.6375    0.6293       240\n",
            "\n",
            "\n",
            "================================================================================\n",
            "OVERALL METRICS\n",
            "================================================================================\n",
            "  Accuracy:        0.6375\n",
            "  Macro F1-Score:  0.3606\n",
            "  Weighted F1:     0.6293\n",
            "\n",
            "================================================================================\n",
            "LANGUAGE-SPECIFIC PERFORMANCE\n",
            "================================================================================\n",
            "\n",
            "  Arabic:\n",
            "    Samples: 39\n",
            "    Accuracy: 0.6667\n",
            "    Macro F1: 0.2982\n",
            "\n",
            "  English:\n",
            "    Samples: 45\n",
            "    Accuracy: 0.7556\n",
            "    Macro F1: 0.3668\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX\n",
            "================================================================================\n",
            "\n",
            "True (rows) vs Predicted (columns):\n",
            "                          Unbiased  Biased Against Palestine  \\\n",
            "Unbiased                       112                        39   \n",
            "Biased Against Palestine        23                        39   \n",
            "Biased Against Israel            5                         1   \n",
            "Others                           8                         5   \n",
            "\n",
            "                          Biased Against Israel  Others  \n",
            "Unbiased                                      0       6  \n",
            "Biased Against Palestine                      0       0  \n",
            "Biased Against Israel                         0       0  \n",
            "Others                                        0       2  \n",
            "\n",
            "================================================================================\n",
            "TESTING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE PREDICTIONS\n",
            "================================================================================\n",
            "\n",
            "[Example 1]\n",
            "  Text: Hamas terrorists launched brutal attacks on innocent Israeli civilians.\n",
            "  Prediction: Biased Against Palestine\n",
            "  Confidence:\n",
            "    Unbiased: 0.1101\n",
            "    Biased Against Palestine: 0.7776\n",
            "    Biased Against Israel: 0.0133\n",
            "    Others: 0.0990\n",
            "\n",
            "[Example 2]\n",
            "  Text: Israeli forces killed dozens of Palestinian civilians in Gaza today.\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.5263\n",
            "    Biased Against Palestine: 0.2403\n",
            "    Biased Against Israel: 0.1414\n",
            "    Others: 0.0921\n",
            "\n",
            "[Example 3]\n",
            "  Text: The conflict continues with casualties on both sides.\n",
            "  Prediction: Others\n",
            "  Confidence:\n",
            "    Unbiased: 0.3794\n",
            "    Biased Against Palestine: 0.1432\n",
            "    Biased Against Israel: 0.0284\n",
            "    Others: 0.4490\n",
            "\n",
            "[Example 4]\n",
            "  Text: Civilians are suffering due to the brutal blockade.\n",
            "  Prediction: Biased Against Palestine\n",
            "  Confidence:\n",
            "    Unbiased: 0.2450\n",
            "    Biased Against Palestine: 0.4373\n",
            "    Biased Against Israel: 0.0151\n",
            "    Others: 0.3025\n",
            "\n",
            "[Example 5]\n",
            "  Text: الاحتلال الإسرائيلي يقصف المدنيين في غزة\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4870\n",
            "    Biased Against Palestine: 0.1521\n",
            "    Biased Against Israel: 0.1993\n",
            "    Others: 0.1616\n",
            "\n",
            "[Example 6]\n",
            "  Text: حماس تطلق صواريخ على المدن الإسرائيلية\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.5246\n",
            "    Biased Against Palestine: 0.1709\n",
            "    Biased Against Israel: 0.1164\n",
            "    Others: 0.1881\n",
            "\n",
            "[Example 7]\n",
            "  Text: استمرار الصراع مع سقوط ضحايا من الجانبين\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4506\n",
            "    Biased Against Palestine: 0.1633\n",
            "    Biased Against Israel: 0.0424\n",
            "    Others: 0.3437\n",
            "\n",
            "[Example 8]\n",
            "  Text: قامت القوات باستهداف المدنيين العزل في قطاع غزة\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4236\n",
            "    Biased Against Palestine: 0.3273\n",
            "    Biased Against Israel: 0.0280\n",
            "    Others: 0.2211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Force reinstall specific compatible versions\n",
        "!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -U transformers datasets accelerate triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f5wnsvt9dUat",
        "outputId": "bf5920f3-d832-40a2-8459-812c53c9205c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (3.5.0)\n",
            "Collecting triton\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading datasets-4.4.2-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed datasets-4.4.2 pyarrow-22.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "bc8a0849684249dd8f33536f80a5a6d0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "XLM-RoBERTa Training for FIGNEWS-2024 (COMPLETE FIXED VERSION)\n",
        "================================================================\n",
        "Fixes applied:\n",
        "1. Uses BOTH Arabic MT and English MT columns (2x dataset via vertical concatenation)\n",
        "2. Capped class weights (max 3.0) to prevent training instability\n",
        "3. Google Drive checkpoint saving for best model\n",
        "4. Proper device management for GPU inference\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Core ML libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Transformers\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Google Drive (for Colab)\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"XLM-ROBERTA TRAINING WITH MT AUGMENTATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration for XLM-RoBERTa training\"\"\"\n",
        "\n",
        "    # File paths\n",
        "    MAIN_FILE = \"/content/Main.xlsx\"\n",
        "    IAA_FILES = [\"/content/IAA-1.xlsx\", \"/content/IAA-2.xlsx\", \"/content/IAA-3.xlsx\", \"/content/IAA-4.xlsx\"]\n",
        "\n",
        "    # Google Drive path for saving best model\n",
        "    DRIVE_MOUNT_PATH = \"/content/drive\"\n",
        "    MODEL_SAVE_PATH = \"/content/drive/MyDrive/xlm_roberta_best_model\"\n",
        "\n",
        "    # MT Column names\n",
        "    ARABIC_MT_COL = \"Arabic MT\"\n",
        "    ENGLISH_MT_COL = \"English MT\"\n",
        "\n",
        "    # Label mapping\n",
        "    LABEL_MAP = {\n",
        "        'Unbiased': 'Unbiased',\n",
        "        'Biased against Palestine': 'Biased Against Palestine',\n",
        "        'Biased Against Palestine': 'Biased Against Palestine',\n",
        "        'Biased against Israel': 'Biased Against Israel',\n",
        "        'Biased Against Israel': 'Biased Against Israel',\n",
        "        'Unclear': 'Others',\n",
        "        'Biased against others': 'Others',\n",
        "        'Biased against both': 'Others',\n",
        "        'Biased against both Palestine and Israel': 'Others',\n",
        "        'Not Applicable': 'Others',\n",
        "        'Others': 'Others'\n",
        "    }\n",
        "\n",
        "    TARGET_LABELS = ['Unbiased', 'Biased Against Palestine', 'Biased Against Israel', 'Others']\n",
        "    LABEL2ID = {label: idx for idx, label in enumerate(TARGET_LABELS)}\n",
        "    ID2LABEL = {idx: label for label, idx in LABEL2ID.items()}\n",
        "\n",
        "    # Model configuration\n",
        "    MODEL_NAME = \"xlm-roberta-base\"\n",
        "\n",
        "    # Training parameters\n",
        "    IAA_TRAIN_SPLIT = 0.8\n",
        "    RANDOM_STATE = 42\n",
        "    MAX_CLASS_WEIGHT = 3.0  # Cap to prevent extreme weights\n",
        "\n",
        "    # Training arguments - optimized for 2x dataset\n",
        "    TRAINING_ARGS = {\n",
        "        \"output_dir\": \"./results_xlm_roberta_mt\",\n",
        "        \"num_train_epochs\": 4,\n",
        "        \"per_device_train_batch_size\": 16,\n",
        "        \"per_device_eval_batch_size\": 16,\n",
        "        \"learning_rate\": 2e-5,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"eval_strategy\": \"epoch\",\n",
        "        \"save_strategy\": \"epoch\",\n",
        "        \"save_total_limit\": 1,  # Keep only best checkpoint\n",
        "        \"load_best_model_at_end\": True,\n",
        "        \"metric_for_best_model\": \"f1_macro\",\n",
        "        \"greater_is_better\": True,\n",
        "        \"logging_steps\": 100,\n",
        "        \"warmup_steps\": 300,  # Increased for larger dataset\n",
        "        \"fp16\": True,  # Mixed precision for faster training\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# GOOGLE DRIVE SETUP\n",
        "# ============================================================================\n",
        "\n",
        "def setup_google_drive():\n",
        "    \"\"\"Mount Google Drive and create save directory.\"\"\"\n",
        "    print(\"\\n[SETUP] Configuring Google Drive...\")\n",
        "\n",
        "    # Mount drive if not already mounted\n",
        "    if not os.path.exists(Config.DRIVE_MOUNT_PATH):\n",
        "        print(\"  Mounting Google Drive...\")\n",
        "        drive.mount(Config.DRIVE_MOUNT_PATH)\n",
        "    else:\n",
        "        print(\"  Google Drive already mounted ✓\")\n",
        "\n",
        "    # Create save directory if it doesn't exist\n",
        "    save_dir = os.path.dirname(Config.MODEL_SAVE_PATH)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "        print(f\"  Created directory: {save_dir}\")\n",
        "\n",
        "    print(f\"  Model will be saved to: {Config.MODEL_SAVE_PATH}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# DATA LOADING & PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "def load_and_clean_data() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Load MAIN and IAA files, filter out rows with missing Bias labels.\"\"\"\n",
        "    print(\"\\n[STEP 1] Loading and cleaning data...\")\n",
        "\n",
        "    # Load MAIN file\n",
        "    print(f\"  Loading {Config.MAIN_FILE}...\")\n",
        "    main_df = pd.read_excel(Config.MAIN_FILE)\n",
        "    initial_main_count = len(main_df)\n",
        "\n",
        "    # Filter out missing Bias labels from MAIN\n",
        "    main_df = main_df[main_df['Bias'].notna() & (main_df['Bias'] != '')]\n",
        "    filtered_main_count = len(main_df)\n",
        "    print(f\"    MAIN: {initial_main_count} rows → {filtered_main_count} rows (removed {initial_main_count - filtered_main_count} with missing labels)\")\n",
        "\n",
        "    # Load and concatenate IAA files\n",
        "    iaa_dfs = []\n",
        "    for iaa_file in Config.IAA_FILES:\n",
        "        if os.path.exists(iaa_file):\n",
        "            print(f\"  Loading {iaa_file}...\")\n",
        "            iaa_df_temp = pd.read_excel(iaa_file)\n",
        "            initial_count = len(iaa_df_temp)\n",
        "\n",
        "            # Check both 'Bias' and 'Bais' (typo in IAA files)\n",
        "            if 'Bais' in iaa_df_temp.columns:\n",
        "                iaa_df_temp['Bias'] = iaa_df_temp['Bais']\n",
        "\n",
        "            iaa_df_temp = iaa_df_temp[iaa_df_temp['Bias'].notna() & (iaa_df_temp['Bias'] != '')]\n",
        "            filtered_count = len(iaa_df_temp)\n",
        "\n",
        "            if filtered_count > 0:\n",
        "                iaa_dfs.append(iaa_df_temp)\n",
        "                print(f\"    {iaa_file}: {initial_count} rows → {filtered_count} rows\")\n",
        "            else:\n",
        "                print(f\"    {iaa_file}: No valid labels found, skipping.\")\n",
        "        else:\n",
        "            print(f\"  Warning: {iaa_file} not found, skipping.\")\n",
        "\n",
        "    # Concatenate all IAA data\n",
        "    if iaa_dfs:\n",
        "        iaa_df = pd.concat(iaa_dfs, ignore_index=True)\n",
        "        print(f\"\\n  Total IAA data: {len(iaa_df)} rows with valid labels\")\n",
        "    else:\n",
        "        print(\"\\n  Warning: No valid IAA data found!\")\n",
        "        iaa_df = pd.DataFrame()\n",
        "\n",
        "    return main_df, iaa_df\n",
        "\n",
        "\n",
        "def augment_with_mt(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Augment dataset by concatenating Arabic MT and English MT vertically.\n",
        "    This doubles the dataset size: each row becomes 2 samples.\n",
        "    \"\"\"\n",
        "    print(\"\\n[MT AUGMENTATION] Creating 2x dataset with Arabic MT + English MT...\")\n",
        "\n",
        "    # Verify MT columns exist\n",
        "    if Config.ARABIC_MT_COL not in df.columns or Config.ENGLISH_MT_COL not in df.columns:\n",
        "        print(f\"  ⚠️ WARNING: MT columns not found!\")\n",
        "        print(f\"  Available columns: {df.columns.tolist()}\")\n",
        "        print(f\"  Skipping MT augmentation...\")\n",
        "        return df\n",
        "\n",
        "    original_count = len(df)\n",
        "\n",
        "    # Create Arabic MT samples\n",
        "    arabic_mt_df = df[[Config.ARABIC_MT_COL, 'Bias_Mapped']].copy()\n",
        "    arabic_mt_df.rename(columns={Config.ARABIC_MT_COL: 'Text'}, inplace=True)\n",
        "    arabic_mt_df = arabic_mt_df[arabic_mt_df['Text'].notna() & (arabic_mt_df['Text'] != '')]\n",
        "\n",
        "    # Create English MT samples\n",
        "    english_mt_df = df[[Config.ENGLISH_MT_COL, 'Bias_Mapped']].copy()\n",
        "    english_mt_df.rename(columns={Config.ENGLISH_MT_COL: 'Text'}, inplace=True)\n",
        "    english_mt_df = english_mt_df[english_mt_df['Text'].notna() & (english_mt_df['Text'] != '')]\n",
        "\n",
        "    # Concatenate vertically\n",
        "    augmented_df = pd.concat([arabic_mt_df, english_mt_df], ignore_index=True)\n",
        "\n",
        "    print(f\"  Original dataset: {original_count} samples\")\n",
        "    print(f\"  After MT augmentation: {len(augmented_df)} samples\")\n",
        "    print(f\"    - Arabic MT: {len(arabic_mt_df)} samples\")\n",
        "    print(f\"    - English MT: {len(english_mt_df)} samples\")\n",
        "    print(f\"  Augmentation ratio: {len(augmented_df) / original_count:.2f}x\")\n",
        "\n",
        "    return augmented_df\n",
        "\n",
        "\n",
        "def map_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Map raw bias labels to standardized 4-class labels.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['Bias_Mapped'] = df['Bias'].map(Config.LABEL_MAP)\n",
        "\n",
        "    # Handle any unmapped labels\n",
        "    unmapped = df[df['Bias_Mapped'].isna()]['Bias'].unique()\n",
        "    if len(unmapped) > 0:\n",
        "        print(f\"  ⚠️ WARNING: Unmapped labels found: {unmapped}\")\n",
        "        print(f\"  These will be mapped to 'Others'\")\n",
        "        df['Bias_Mapped'] = df['Bias_Mapped'].fillna('Others')\n",
        "    else:\n",
        "        print(f\"  ✓ All labels mapped successfully\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_majority_vote(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Apply majority voting to IAA data grouped by Text/ID.\"\"\"\n",
        "    print(\"\\n  Applying majority vote to collapse duplicate annotations...\")\n",
        "\n",
        "    # Create a unique text identifier\n",
        "    if 'ID' in df.columns:\n",
        "        df['Text_ID'] = df['ID'].astype(str) + \"_\" + df['Text'].astype(str).str[:50]\n",
        "    else:\n",
        "        df['Text_ID'] = df['Text'].astype(str).str[:50]\n",
        "\n",
        "    gold_standard_rows = []\n",
        "\n",
        "    for text_id, group in df.groupby('Text_ID'):\n",
        "        # Get most common label (mode)\n",
        "        labels = group['Bias_Mapped'].tolist()\n",
        "        label_counts = Counter(labels)\n",
        "        majority_label = label_counts.most_common(1)[0][0]\n",
        "\n",
        "        # Take first row and update its label\n",
        "        gold_row = group.iloc[0].copy()\n",
        "        gold_row['Bias_Mapped'] = majority_label\n",
        "        gold_row['Annotator_Count'] = len(group)\n",
        "        gold_standard_rows.append(gold_row)\n",
        "\n",
        "    result_df = pd.DataFrame(gold_standard_rows)\n",
        "    print(f\"    Collapsed {len(df)} annotations → {len(result_df)} unique texts\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "\n",
        "def create_train_test_split(main_df: pd.DataFrame, iaa_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Create training and test sets following the silver/gold strategy.\"\"\"\n",
        "    print(\"\\n[STEP 2] Creating train/test splits...\")\n",
        "\n",
        "    # Get unique text IDs from IAA\n",
        "    unique_ids = iaa_df['Text_ID'].unique() if 'Text_ID' in iaa_df.columns else iaa_df['ID'].unique()\n",
        "    print(f\"  Total unique IAA texts: {len(unique_ids)}\")\n",
        "\n",
        "    # Split by IDs (80/20)\n",
        "    train_ids, test_ids = train_test_split(\n",
        "        unique_ids,\n",
        "        test_size=(1 - Config.IAA_TRAIN_SPLIT),\n",
        "        random_state=Config.RANDOM_STATE,\n",
        "        stratify=None\n",
        "    )\n",
        "\n",
        "    print(f\"  IAA split: {len(train_ids)} train IDs, {len(test_ids)} test IDs\")\n",
        "\n",
        "    # Split IAA data\n",
        "    if 'Text_ID' in iaa_df.columns:\n",
        "        iaa_train = iaa_df[iaa_df['Text_ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['Text_ID'].isin(test_ids)].copy()\n",
        "    else:\n",
        "        iaa_train = iaa_df[iaa_df['ID'].isin(train_ids)].copy()\n",
        "        iaa_test = iaa_df[iaa_df['ID'].isin(test_ids)].copy()\n",
        "\n",
        "    # Apply majority vote to both\n",
        "    iaa_train_collapsed = apply_majority_vote(iaa_train)\n",
        "    iaa_test_collapsed = apply_majority_vote(iaa_test)\n",
        "\n",
        "    # IMPORTANT: Apply MT augmentation BEFORE combining with MAIN\n",
        "    print(\"\\n[STEP 3] Applying MT augmentation to training data...\")\n",
        "    main_df_augmented = augment_with_mt(main_df)\n",
        "    iaa_train_augmented = augment_with_mt(iaa_train_collapsed)\n",
        "\n",
        "    # Combine MAIN + IAA_train for training set\n",
        "    train_df = pd.concat([main_df_augmented, iaa_train_augmented], ignore_index=True)\n",
        "\n",
        "    # Also augment test set for consistency\n",
        "    print(\"\\n[STEP 4] Applying MT augmentation to test data...\")\n",
        "    test_df = augment_with_mt(iaa_test_collapsed)\n",
        "\n",
        "    print(f\"\\n  Final training set: {len(train_df)} samples (after MT augmentation)\")\n",
        "    print(f\"  Final test set: {len(test_df)} samples (after MT augmentation)\")\n",
        "\n",
        "    # Print class distribution\n",
        "    print(\"\\n  Training set class distribution:\")\n",
        "    train_dist = train_df['Bias_Mapped'].value_counts()\n",
        "    print(train_dist)\n",
        "    print(\"\\n  Class proportions:\")\n",
        "    print((train_dist / len(train_df) * 100).round(2))\n",
        "\n",
        "    print(\"\\n  Test set class distribution:\")\n",
        "    print(test_df['Bias_Mapped'].value_counts())\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# CUSTOM TRAINER WITH CAPPED CLASS WEIGHTS\n",
        "# ============================================================================\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Custom Trainer that applies CAPPED class weights to loss function.\"\"\"\n",
        "\n",
        "    def __init__(self, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        \"\"\"Override compute_loss to use weighted CrossEntropyLoss.\"\"\"\n",
        "        labels = inputs.pop(\"labels\")\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Compute weighted loss\n",
        "        if self.class_weights is not None:\n",
        "            # Move weights to same device as logits\n",
        "            weights = self.class_weights.to(logits.device)\n",
        "            loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
        "        else:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# XLM-ROBERTA MODEL\n",
        "# ============================================================================\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for training.\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1_macro = f1_score(labels, predictions, average='macro')\n",
        "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted\n",
        "    }\n",
        "\n",
        "\n",
        "def prepare_dataset(df: pd.DataFrame, tokenizer, text_column: str = 'Text'):\n",
        "    \"\"\"Prepare dataset for transformer training.\"\"\"\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(\n",
        "            examples['text'],\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "    # Prepare data\n",
        "    data_dict = {\n",
        "        'text': df[text_column].tolist(),\n",
        "        'label': df['Bias_Mapped'].map(Config.LABEL2ID).tolist()\n",
        "    }\n",
        "\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    return tokenized_dataset\n",
        "\n",
        "\n",
        "class XLMRoBERTaBiasDetector:\n",
        "    \"\"\"XLM-RoBERTa model for bias detection with capped class weights.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.trainer = None\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"\\n[MODEL] Initializing XLM-RoBERTa Bias Detector\")\n",
        "        print(f\"  Model: {Config.MODEL_NAME}\")\n",
        "        print(f\"  Device: {self.device}\")\n",
        "\n",
        "    def train(self, train_df: pd.DataFrame, eval_df: pd.DataFrame = None):\n",
        "        \"\"\"Train the model with capped class weight balancing.\"\"\"\n",
        "        print(\"\\n[STEP 5] Training XLM-RoBERTa with Capped Class Weights...\")\n",
        "\n",
        "        # Load tokenizer and model\n",
        "        print(f\"  Loading tokenizer and model: {Config.MODEL_NAME}...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_NAME)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            Config.MODEL_NAME,\n",
        "            num_labels=len(Config.TARGET_LABELS),\n",
        "            id2label=Config.ID2LABEL,\n",
        "            label2id=Config.LABEL2ID\n",
        "        )\n",
        "\n",
        "        # Move model to device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Calculate class weights with capping\n",
        "        print(\"\\n  Calculating CAPPED class weights...\")\n",
        "        labels = train_df['Bias_Mapped'].map(Config.LABEL2ID).values\n",
        "        unique_labels = np.unique(labels)\n",
        "\n",
        "        # Compute balanced weights\n",
        "        class_weights = compute_class_weight(\n",
        "            class_weight='balanced',\n",
        "            classes=unique_labels,\n",
        "            y=labels\n",
        "        )\n",
        "\n",
        "        # CAP the weights to prevent extreme values\n",
        "        class_weights = np.clip(class_weights, a_min=None, a_max=Config.MAX_CLASS_WEIGHT)\n",
        "\n",
        "        # Convert to tensor\n",
        "        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "        print(f\"  Class weights (capped at {Config.MAX_CLASS_WEIGHT}):\")\n",
        "        for label_id, weight in zip(unique_labels, class_weights):\n",
        "            label_name = Config.ID2LABEL[label_id]\n",
        "            print(f\"    {label_name}: {weight:.4f}\")\n",
        "\n",
        "        # Prepare datasets\n",
        "        print(\"\\n  Preparing datasets...\")\n",
        "        train_dataset = prepare_dataset(train_df, self.tokenizer)\n",
        "        eval_dataset = None\n",
        "        if eval_df is not None and len(eval_df) > 0:\n",
        "            eval_dataset = prepare_dataset(eval_df, self.tokenizer)\n",
        "\n",
        "        # Training arguments - save to local first, then copy to Drive\n",
        "        training_args = TrainingArguments(\n",
        "            **Config.TRAINING_ARGS,\n",
        "            report_to=\"none\"\n",
        "        )\n",
        "\n",
        "        # Use custom weighted trainer\n",
        "        self.trainer = WeightedTrainer(\n",
        "            class_weights=class_weights_tensor,\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=eval_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] if eval_dataset else None\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        print(\"\\n  Starting training...\")\n",
        "        print(f\"    Epochs: {Config.TRAINING_ARGS['num_train_epochs']}\")\n",
        "        print(f\"    Batch size: {Config.TRAINING_ARGS['per_device_train_batch_size']}\")\n",
        "        print(f\"    Learning rate: {Config.TRAINING_ARGS['learning_rate']}\")\n",
        "        print(f\"    Using capped class weights: Yes ✓ (max={Config.MAX_CLASS_WEIGHT})\")\n",
        "        print(f\"    Mixed precision (fp16): {Config.TRAINING_ARGS['fp16']}\")\n",
        "\n",
        "        self.trainer.train()\n",
        "\n",
        "        print(\"\\n  ✓ Training completed successfully!\")\n",
        "\n",
        "        # Save best model to Google Drive\n",
        "        self.save_to_drive()\n",
        "\n",
        "    def save_to_drive(self):\n",
        "        \"\"\"Save the best model to Google Drive.\"\"\"\n",
        "        print(\"\\n[SAVING] Copying best model to Google Drive...\")\n",
        "\n",
        "        try:\n",
        "            # Save model and tokenizer to Drive\n",
        "            self.model.save_pretrained(Config.MODEL_SAVE_PATH)\n",
        "            self.tokenizer.save_pretrained(Config.MODEL_SAVE_PATH)\n",
        "\n",
        "            print(f\"  ✓ Model saved to: {Config.MODEL_SAVE_PATH}\")\n",
        "            print(f\"  You can now use this model for inference!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠️ Error saving to Drive: {e}\")\n",
        "            print(f\"  Model is still available in local directory: {Config.TRAINING_ARGS['output_dir']}\")\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[str]:\n",
        "        \"\"\"Predict labels for texts with proper device management.\"\"\"\n",
        "        if not texts:\n",
        "            return []\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Move inputs to the same device as model\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return [Config.ID2LABEL[pred.item()] for pred in predictions]\n",
        "\n",
        "    def predict_proba(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Predict probabilities for each class with proper device management.\"\"\"\n",
        "        if not texts:\n",
        "            return np.array([])\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = self.tokenizer(\n",
        "            texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Move inputs to the same device as model\n",
        "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "            probs = torch.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "        return probs.cpu().numpy()\n",
        "\n",
        "    def evaluate(self, test_df: pd.DataFrame):\n",
        "        \"\"\"Evaluate model on test set with detailed metrics.\"\"\"\n",
        "        print(\"\\n[STEP 6] Evaluating XLM-RoBERTa...\")\n",
        "\n",
        "        texts = test_df['Text'].tolist()\n",
        "        true_labels = test_df['Bias_Mapped'].tolist()\n",
        "\n",
        "        # Get predictions\n",
        "        print(\"  Generating predictions...\")\n",
        "        predictions = self.predict(texts)\n",
        "\n",
        "        # Overall metrics\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CLASSIFICATION REPORT\")\n",
        "        print(\"=\"*80)\n",
        "        print(classification_report(\n",
        "            true_labels,\n",
        "            predictions,\n",
        "            target_names=Config.TARGET_LABELS,\n",
        "            digits=4\n",
        "        ))\n",
        "\n",
        "        acc = accuracy_score(true_labels, predictions)\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro')\n",
        "        f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"OVERALL METRICS\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"  Accuracy:        {acc:.4f}\")\n",
        "        print(f\"  Macro F1-Score:  {f1_macro:.4f}\")\n",
        "        print(f\"  Weighted F1:     {f1_weighted:.4f}\")\n",
        "\n",
        "        # Confusion matrix\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CONFUSION MATRIX\")\n",
        "        print(\"=\"*80)\n",
        "        cm = confusion_matrix(true_labels, predictions, labels=Config.TARGET_LABELS)\n",
        "        print(\"\\nTrue Labels (rows) vs Predicted Labels (columns):\")\n",
        "        cm_df = pd.DataFrame(cm, index=Config.TARGET_LABELS, columns=Config.TARGET_LABELS)\n",
        "        print(cm_df)\n",
        "\n",
        "        return {\n",
        "            'predictions': predictions,\n",
        "            'accuracy': acc,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function.\"\"\"\n",
        "\n",
        "    # Set random seeds\n",
        "    np.random.seed(Config.RANDOM_STATE)\n",
        "    torch.manual_seed(Config.RANDOM_STATE)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(Config.RANDOM_STATE)\n",
        "\n",
        "    # Setup Google Drive\n",
        "    setup_google_drive()\n",
        "\n",
        "    # Load and prepare data\n",
        "    main_df, iaa_df = load_and_clean_data()\n",
        "\n",
        "    # Map labels\n",
        "    print(\"\\n[PREPROCESSING] Mapping labels...\")\n",
        "    main_df = map_labels(main_df)\n",
        "    if len(iaa_df) > 0:\n",
        "        iaa_df = map_labels(iaa_df)\n",
        "\n",
        "    # Create splits (includes MT augmentation)\n",
        "    train_df, test_df = create_train_test_split(main_df, iaa_df)\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = XLMRoBERTaBiasDetector()\n",
        "    model.train(train_df, test_df)\n",
        "\n",
        "    # Evaluate\n",
        "    if len(test_df) > 0:\n",
        "        results = model.evaluate(test_df)\n",
        "    else:\n",
        "        print(\"\\n  Warning: No test data available for evaluation\")\n",
        "        results = None\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TRAINING & EVALUATION COMPLETE\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\n✓ Best model saved to: {Config.MODEL_SAVE_PATH}\")\n",
        "\n",
        "    return model, results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# INFERENCE EXAMPLES\n",
        "# ============================================================================\n",
        "\n",
        "def test_predictions(model: XLMRoBERTaBiasDetector):\n",
        "    \"\"\"Test the model with example texts.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXAMPLE PREDICTIONS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    sample_texts = [\n",
        "        # English examples\n",
        "        \"Hamas terrorists launched brutal attacks on innocent Israeli civilians.\",\n",
        "        \"Israeli forces killed dozens of Palestinian civilians in Gaza today.\",\n",
        "        \"The conflict continues with casualties on both sides.\",\n",
        "        \"Civilians are suffering due to the brutal blockade.\",\n",
        "\n",
        "        # Arabic examples\n",
        "        \"الاحتلال الإسرائيلي يقصف المدنيين في غزة\",\n",
        "        \"حماس تطلق صواريخ على المدن الإسرائيلية\",\n",
        "        \"استمرار الصراع مع سقوط ضحايا من الجانبين\",\n",
        "        \"قامت القوات باستهداف المدنيين العزل في قطاع غزة\"\n",
        "    ]\n",
        "\n",
        "    predictions = model.predict(sample_texts)\n",
        "    probabilities = model.predict_proba(sample_texts)\n",
        "\n",
        "    for i, (text, pred, probs) in enumerate(zip(sample_texts, predictions, probabilities), 1):\n",
        "        print(f\"\\n[Example {i}]\")\n",
        "        print(f\"  Text: {text}\")\n",
        "        print(f\"  Prediction: {pred}\")\n",
        "        print(f\"  Confidence:\")\n",
        "        for label, prob in zip(Config.TARGET_LABELS, probs):\n",
        "            print(f\"    {label}: {prob:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run main pipeline\n",
        "    model, results = main()\n",
        "\n",
        "    # Test with examples\n",
        "    if model is not None:\n",
        "        test_predictions(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "637e0fa9cadf45b0af7ec01d2ed41654",
            "36622c2a65d7414ca94d1bf53a12f2ab",
            "88976e54a7b043f19babc96f0be021a6",
            "4cadeda8d5ef480a8a30c487971101ed",
            "d65f7d15d9994e61890c2dda9fd43e48",
            "8e74e977a73442eeb71142c461d1dda7",
            "a3f2c423ffcc471aaf6ffe31e97e66f6",
            "0a07b5f7f01c4488bbd294630fe313e8",
            "b2f5e36ec6534ef6b99623255366ed10",
            "12cba7a6dcb94f0092f7f68ff17c9960",
            "54108fab92d747a8b90a9ef7887d67e3",
            "312e4672649d4995b9d7bc264f9eec9a",
            "e6f5f8ad6a34451eb18b3219aa54e6e6",
            "80c471a2ff964acc821523adc50cb204",
            "cb5f7d7ad9f3453e9d4bcb4f04bf254c",
            "e98a7d7deb9141f39c6d5dc730d1128e",
            "138eee1378c442178a6bd767abfcce4a",
            "592ba0024ee848608405ae468ab0e4a0",
            "1d5d0e352c0f49e98cb3cd0b967b61cc",
            "0c3b2bd848da431f9c3606aeb35d9afe",
            "efc3e9cd736847f7903645e3b9fa807c",
            "e03cb979cdab4761a3eb9ae2c7fe4778"
          ]
        },
        "id": "SsZBFMKI-05q",
        "outputId": "8ca34ce2-0fb4-468f-e989-c8eabc59e315"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "XLM-ROBERTA TRAINING WITH MT AUGMENTATION\n",
            "================================================================================\n",
            "\n",
            "[SETUP] Configuring Google Drive...\n",
            "  Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "  Model will be saved to: /content/drive/MyDrive/xlm_roberta_best_model\n",
            "\n",
            "[STEP 1] Loading and cleaning data...\n",
            "  Loading /content/Main.xlsx...\n",
            "    MAIN: 13500 rows → 10800 rows (removed 2700 with missing labels)\n",
            "  Loading /content/IAA-1.xlsx...\n",
            "    /content/IAA-1.xlsx: 1200 rows → 1200 rows\n",
            "  Loading /content/IAA-2.xlsx...\n",
            "    /content/IAA-2.xlsx: 1200 rows → 1200 rows\n",
            "  Loading /content/IAA-3.xlsx...\n",
            "    /content/IAA-3.xlsx: No valid labels found, skipping.\n",
            "  Loading /content/IAA-4.xlsx...\n",
            "    /content/IAA-4.xlsx: No valid labels found, skipping.\n",
            "\n",
            "  Total IAA data: 2400 rows with valid labels\n",
            "\n",
            "[PREPROCESSING] Mapping labels...\n",
            "  ✓ All labels mapped successfully\n",
            "  ✓ All labels mapped successfully\n",
            "\n",
            "[STEP 2] Creating train/test splits...\n",
            "  Total unique IAA texts: 1115\n",
            "  IAA split: 892 train IDs, 223 test IDs\n",
            "\n",
            "  Applying majority vote to collapse duplicate annotations...\n",
            "    Collapsed 1920 annotations → 960 unique texts\n",
            "\n",
            "  Applying majority vote to collapse duplicate annotations...\n",
            "    Collapsed 480 annotations → 240 unique texts\n",
            "\n",
            "[STEP 3] Applying MT augmentation to training data...\n",
            "\n",
            "[MT AUGMENTATION] Creating 2x dataset with Arabic MT + English MT...\n",
            "  Original dataset: 10800 samples\n",
            "  After MT augmentation: 21600 samples\n",
            "    - Arabic MT: 10800 samples\n",
            "    - English MT: 10800 samples\n",
            "  Augmentation ratio: 2.00x\n",
            "\n",
            "[MT AUGMENTATION] Creating 2x dataset with Arabic MT + English MT...\n",
            "  Original dataset: 960 samples\n",
            "  After MT augmentation: 1920 samples\n",
            "    - Arabic MT: 960 samples\n",
            "    - English MT: 960 samples\n",
            "  Augmentation ratio: 2.00x\n",
            "\n",
            "[STEP 4] Applying MT augmentation to test data...\n",
            "\n",
            "[MT AUGMENTATION] Creating 2x dataset with Arabic MT + English MT...\n",
            "  Original dataset: 240 samples\n",
            "  After MT augmentation: 480 samples\n",
            "    - Arabic MT: 240 samples\n",
            "    - English MT: 240 samples\n",
            "  Augmentation ratio: 2.00x\n",
            "\n",
            "  Final training set: 23520 samples (after MT augmentation)\n",
            "  Final test set: 480 samples (after MT augmentation)\n",
            "\n",
            "  Training set class distribution:\n",
            "Bias_Mapped\n",
            "Unbiased                    14850\n",
            "Biased Against Palestine     6338\n",
            "Others                       1742\n",
            "Biased Against Israel         590\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Class proportions:\n",
            "Bias_Mapped\n",
            "Unbiased                    63.14\n",
            "Biased Against Palestine    26.95\n",
            "Others                       7.41\n",
            "Biased Against Israel        2.51\n",
            "Name: count, dtype: float64\n",
            "\n",
            "  Test set class distribution:\n",
            "Bias_Mapped\n",
            "Unbiased                    314\n",
            "Biased Against Palestine    124\n",
            "Others                       30\n",
            "Biased Against Israel        12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "[MODEL] Initializing XLM-RoBERTa Bias Detector\n",
            "  Model: xlm-roberta-base\n",
            "  Device: cuda\n",
            "\n",
            "[STEP 5] Training XLM-RoBERTa with Capped Class Weights...\n",
            "  Loading tokenizer and model: xlm-roberta-base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Calculating CAPPED class weights...\n",
            "  Class weights (capped at 3.0):\n",
            "    Unbiased: 0.3960\n",
            "    Biased Against Palestine: 0.9277\n",
            "    Biased Against Israel: 3.0000\n",
            "    Others: 3.0000\n",
            "\n",
            "  Preparing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23520 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "637e0fa9cadf45b0af7ec01d2ed41654"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "312e4672649d4995b9d7bc264f9eec9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Starting training...\n",
            "    Epochs: 4\n",
            "    Batch size: 16\n",
            "    Learning rate: 2e-05\n",
            "    Using capped class weights: Yes ✓ (max=3.0)\n",
            "    Mixed precision (fp16): True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5880' max='5880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5880/5880 45:32, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.277400</td>\n",
              "      <td>1.288809</td>\n",
              "      <td>0.372917</td>\n",
              "      <td>0.219193</td>\n",
              "      <td>0.339835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.253200</td>\n",
              "      <td>1.256718</td>\n",
              "      <td>0.485417</td>\n",
              "      <td>0.278973</td>\n",
              "      <td>0.487792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.223400</td>\n",
              "      <td>1.207785</td>\n",
              "      <td>0.691667</td>\n",
              "      <td>0.346925</td>\n",
              "      <td>0.649107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.226800</td>\n",
              "      <td>1.223570</td>\n",
              "      <td>0.622917</td>\n",
              "      <td>0.337125</td>\n",
              "      <td>0.602748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ✓ Training completed successfully!\n",
            "\n",
            "[SAVING] Copying best model to Google Drive...\n",
            "  ✓ Model saved to: /content/drive/MyDrive/xlm_roberta_best_model\n",
            "  You can now use this model for inference!\n",
            "\n",
            "[STEP 6] Evaluating XLM-RoBERTa...\n",
            "  Generating predictions...\n",
            "\n",
            "================================================================================\n",
            "CLASSIFICATION REPORT\n",
            "================================================================================\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "                Unbiased     0.0000    0.0000    0.0000        12\n",
            "Biased Against Palestine     0.5698    0.3952    0.4667       124\n",
            "   Biased Against Israel     1.0000    0.0667    0.1250        30\n",
            "                  Others     0.7168    0.8949    0.7960       314\n",
            "\n",
            "                accuracy                         0.6917       480\n",
            "               macro avg     0.5717    0.3392    0.3469       480\n",
            "            weighted avg     0.6786    0.6917    0.6491       480\n",
            "\n",
            "\n",
            "================================================================================\n",
            "OVERALL METRICS\n",
            "================================================================================\n",
            "  Accuracy:        0.6917\n",
            "  Macro F1-Score:  0.3469\n",
            "  Weighted F1:     0.6491\n",
            "\n",
            "================================================================================\n",
            "CONFUSION MATRIX\n",
            "================================================================================\n",
            "\n",
            "True Labels (rows) vs Predicted Labels (columns):\n",
            "                          Unbiased  Biased Against Palestine  \\\n",
            "Unbiased                       281                        33   \n",
            "Biased Against Palestine        75                        49   \n",
            "Biased Against Israel           12                         0   \n",
            "Others                          24                         4   \n",
            "\n",
            "                          Biased Against Israel  Others  \n",
            "Unbiased                                      0       0  \n",
            "Biased Against Palestine                      0       0  \n",
            "Biased Against Israel                         0       0  \n",
            "Others                                        0       2  \n",
            "\n",
            "================================================================================\n",
            "TRAINING & EVALUATION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "✓ Best model saved to: /content/drive/MyDrive/xlm_roberta_best_model\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE PREDICTIONS\n",
            "================================================================================\n",
            "\n",
            "[Example 1]\n",
            "  Text: Hamas terrorists launched brutal attacks on innocent Israeli civilians.\n",
            "  Prediction: Biased Against Palestine\n",
            "  Confidence:\n",
            "    Unbiased: 0.1724\n",
            "    Biased Against Palestine: 0.6932\n",
            "    Biased Against Israel: 0.0237\n",
            "    Others: 0.1106\n",
            "\n",
            "[Example 2]\n",
            "  Text: Israeli forces killed dozens of Palestinian civilians in Gaza today.\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4880\n",
            "    Biased Against Palestine: 0.2424\n",
            "    Biased Against Israel: 0.0805\n",
            "    Others: 0.1891\n",
            "\n",
            "[Example 3]\n",
            "  Text: The conflict continues with casualties on both sides.\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4406\n",
            "    Biased Against Palestine: 0.1793\n",
            "    Biased Against Israel: 0.0338\n",
            "    Others: 0.3463\n",
            "\n",
            "[Example 4]\n",
            "  Text: Civilians are suffering due to the brutal blockade.\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4372\n",
            "    Biased Against Palestine: 0.1772\n",
            "    Biased Against Israel: 0.0332\n",
            "    Others: 0.3524\n",
            "\n",
            "[Example 5]\n",
            "  Text: الاحتلال الإسرائيلي يقصف المدنيين في غزة\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4611\n",
            "    Biased Against Palestine: 0.2700\n",
            "    Biased Against Israel: 0.0955\n",
            "    Others: 0.1734\n",
            "\n",
            "[Example 6]\n",
            "  Text: حماس تطلق صواريخ على المدن الإسرائيلية\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4571\n",
            "    Biased Against Palestine: 0.2810\n",
            "    Biased Against Israel: 0.0645\n",
            "    Others: 0.1974\n",
            "\n",
            "[Example 7]\n",
            "  Text: استمرار الصراع مع سقوط ضحايا من الجانبين\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4966\n",
            "    Biased Against Palestine: 0.2330\n",
            "    Biased Against Israel: 0.0737\n",
            "    Others: 0.1968\n",
            "\n",
            "[Example 8]\n",
            "  Text: قامت القوات باستهداف المدنيين العزل في قطاع غزة\n",
            "  Prediction: Unbiased\n",
            "  Confidence:\n",
            "    Unbiased: 0.4974\n",
            "    Biased Against Palestine: 0.2381\n",
            "    Biased Against Israel: 0.0802\n",
            "    Others: 0.1843\n"
          ]
        }
      ]
    }
  ]
}